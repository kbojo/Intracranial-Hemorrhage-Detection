{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import collections\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "from math import ceil, floor, log\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "#import tensorflow.keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import sys\n",
    "\n",
    "# from keras_applications.resnet import ResNet50\n",
    "from keras_applications.inception_v3 import InceptionV3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    " \n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, ShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50, VGG16, VGG19\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_resnet_50\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as preprocess_vgg_16\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Activation, concatenate, Dropout, MaxPooling2D, Conv2D, Flatten\n",
    "from tensorflow.keras.initializers import glorot_normal, he_normal\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model, load_model, Sequential, load_model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "\n",
    "\n",
    "#from tensorflow.nn import sigmoid_cross_entropy_with_logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_data = '../data/input/rsna-intracranial-hemorrhage-detection/stage_2_train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test_data = '../data/input/rsna-intracranial-hemorrhage-detection/stage_2_test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_files(path, data_name):\n",
    "    no =  len(os.listdir(path))\n",
    "    print (f'The {data_name} contains {no} files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size_directory(path, data_name):\n",
    "    size = round(sum([os.path.getsize(f'{path}'+ f'{file}') for file in os.listdir(path)])*(10**-9), 2)\n",
    "    print (f'The size of the {data_name} is {size} GB.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***TRAIN DATA***\n",
      "The size of the Training Data is 395.19 GB.\n",
      "The Training Data contains 752803 files.\n",
      "*******\n",
      "***TEST DATA***\n",
      "The size of the Testing Data is 63.64 GB.\n",
      "The Testing Data contains 121232 files.\n",
      "*******\n",
      "We have 6.2 times more train than test data.\n"
     ]
    }
   ],
   "source": [
    "print('***TRAIN DATA***')\n",
    "get_size_directory(path_train_data, 'Training Data')\n",
    "get_number_of_files(path_train_data, 'Training Data')\n",
    "\n",
    "print('*******')\n",
    "\n",
    "print('***TEST DATA***')\n",
    "get_size_directory(path_test_data, 'Testing Data')\n",
    "get_number_of_files(path_test_data, 'Testing Data')\n",
    "\n",
    "print('*******')\n",
    "\n",
    "print(f'We have {round(len(os.listdir(path_train_data))/len(os.listdir(path_test_data)),1)} times more train than test data.' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_meta_df = pd.read_csv('../data/input/rsna-intracranial-hemorrhage-detection/stage_2_train.csv')\n",
    "# Test submission as test \n",
    "test_meta_df = pd.read_csv('../data/input/rsna-intracranial-hemorrhage-detection/stage_2_sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta_df_shape = train_meta_df.shape\n",
    "test_meta_df_shape = test_meta_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4516842, 2)\n",
      "(727392, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_meta_df_shape)\n",
    "print(test_meta_df_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Seed\n",
    "SEED = 11\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "# Constants\n",
    "TEST_SIZE = 0.2\n",
    "HEIGHT = 256 #VGG 16 has 256x256\n",
    "WIDTH = 256\n",
    "CHANNELS = 3\n",
    "TRAIN_BATCH_SIZE = 64\n",
    "VALID_BATCH_SIZE = 64\n",
    "TEST_BATCH_SIZE = 8\n",
    "SHAPE = (HEIGHT, WIDTH, CHANNELS)\n",
    "\n",
    "# Folders\n",
    "#DATA_DIR = '/kaggle/input/rsna-intracranial-hemorrhage-detection/'\n",
    "PATH_TEST_DATA = path_test_data\n",
    "PATH_TRAIN_DATA = path_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_manual_window(hu_image, min_value, max_value):\n",
    "    hu_image[hu_image < min_value] = min_value\n",
    "    hu_image[hu_image > max_value] = min_value #max_value\n",
    "    return hu_image\n",
    "\n",
    "def rescale_window(dataset):\n",
    "    image = dataset.pixel_array\n",
    "    rescaled_image = image * dataset.RescaleSlope + dataset.RescaleIntercept\n",
    "    rescaled_image[rescaled_image < -1024] = -1024\n",
    "    brain_img = set_manual_window(rescaled_image, 40, 80)\n",
    "    subdural_img = set_manual_window(rescaled_image, 80, 200)\n",
    "    soft_img =set_manual_window(rescaled_image, 40, 380)\n",
    "    \n",
    "    brain_img = (brain_img - 0) / 80\n",
    "    subdural_img = (subdural_img - (-20)) / 200\n",
    "    soft_img = (soft_img - (-150)) / 380\n",
    "    bsb_img = np.array([brain_img, subdural_img, soft_img]).transpose(1,2,0)\n",
    "    return bsb_img\n",
    "\n",
    "def load_dicom_dataset(path, SHAPE):\n",
    "    dataset = pydicom.dcmread(path)\n",
    "    try:\n",
    "        img = rescale_window(dataset)\n",
    "    except:\n",
    "        img = np.zeros(SHAPE)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "        \n",
    "# Generators\n",
    "class TrainDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, dataset, labels, batch_size = 16, img_size = SHAPE, img_dir = PATH_TRAIN_DATA, augment = False, *args, **kwargs):\n",
    "        self.dataset = dataset\n",
    "        self.ids = dataset.index\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.img_dir = img_dir\n",
    "        self.augment = augment\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self): #Number of Batches per Epoch\n",
    "        return int(ceil(len(self.ids) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index): #Generates one Batch of Data\n",
    "        #indices of Batch\n",
    "        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        X, Y = self.__data_generation(indices)\n",
    "        return X, Y\n",
    "\n",
    "    def augmentor(self, image):\n",
    "        augment_img = iaa.Sequential([ iaa.Fliplr(0.25),\n",
    "                                iaa.Flipud(0.10)], random_order = True)       \n",
    "            \n",
    "        image_aug = augment_img.augment_image(image)\n",
    "        return image_aug\n",
    "\n",
    "    def on_epoch_end(self): #Updates Indices after each Epoch\n",
    "        self.indices = np.arange(len(self.ids))\n",
    "        np.random.shuffle(self.indices)\n",
    "\n",
    "    def __data_generation(self, indices): #Generates Data in Size of Batch Size\n",
    "        X = np.empty((self.batch_size, *self.img_size))\n",
    "        Y = np.empty((self.batch_size, 6), dtype=np.float32)\n",
    "        \n",
    "        for i, index in enumerate(indices):\n",
    "            ID = self.ids[index]\n",
    "            \n",
    "            image = load_dicom_dataset(self.img_dir+ID+\".dcm\", SHAPE)\n",
    "            if self.augment:\n",
    "                X[i,] = self.augmentor(image)\n",
    "            else:\n",
    "                X[i,] = image\n",
    "            Y[i,] = self.labels.iloc[index].values        \n",
    "        return X, Y\n",
    "    \n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, dataset,batch_size = 16, img_size = SHAPE, img_dir = PATH_TEST_DATA, *args, **kwargs):\n",
    "        self.dataset = dataset\n",
    "        self.ids = dataset.index\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.img_dir = img_dir\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(ceil(len(self.ids) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        X = self.__data_generation(indices)\n",
    "        return X\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.ids))\n",
    "    \n",
    "    def __data_generation(self, indices):\n",
    "        X = np.empty((self.batch_size, *self.img_size))\n",
    "        \n",
    "        for i, index in enumerate(indices):\n",
    "            ID = self.ids[index]\n",
    "            image = load_dicom_dataset(self.img_dir+ID+\".dcm\", SHAPE)\n",
    "            X[i,] = image              \n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Meta Data Frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_usable_df(df):\n",
    "    label = df.Label.values\n",
    "    new_df = df.ID.str.rsplit(\"_\", n=1, expand=True)\n",
    "    new_df.loc[:, \"label\"] = label\n",
    "    new_df = new_df.rename({0: \"id\", 1: \"subtype\"}, axis=1)\n",
    "    piv_df = pd.pivot_table(new_df, index=\"id\", columns=\"subtype\", values=\"label\")\n",
    "    \n",
    "    return piv_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for Dupicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_meta_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta_df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_meta_df_shape[0] - train_meta_df.shape[0] == 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make usable Data Frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>subtype</th>\n",
       "      <th>any</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID_000012eaf</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_000039fa0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_00005679d</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_00008ce3c</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_0000950d7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "subtype       any  epidural  intraparenchymal  intraventricular  subarachnoid  \\\n",
       "id                                                                              \n",
       "ID_000012eaf    0         0                 0                 0             0   \n",
       "ID_000039fa0    0         0                 0                 0             0   \n",
       "ID_00005679d    0         0                 0                 0             0   \n",
       "ID_00008ce3c    0         0                 0                 0             0   \n",
       "ID_0000950d7    0         0                 0                 0             0   \n",
       "\n",
       "subtype       subdural  \n",
       "id                      \n",
       "ID_000012eaf         0  \n",
       "ID_000039fa0         0  \n",
       "ID_00005679d         0  \n",
       "ID_00008ce3c         0  \n",
       "ID_0000950d7         0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = make_usable_df(train_meta_df)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Check for Duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_meta_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make usable Data Frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>subtype</th>\n",
       "      <th>any</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID_000000e27</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_000009146</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_00007b8cb</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_000134952</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_000176f2a</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "subtype       any  epidural  intraparenchymal  intraventricular  subarachnoid  \\\n",
       "id                                                                              \n",
       "ID_000000e27  0.5       0.5               0.5               0.5           0.5   \n",
       "ID_000009146  0.5       0.5               0.5               0.5           0.5   \n",
       "ID_00007b8cb  0.5       0.5               0.5               0.5           0.5   \n",
       "ID_000134952  0.5       0.5               0.5               0.5           0.5   \n",
       "ID_000176f2a  0.5       0.5               0.5               0.5           0.5   \n",
       "\n",
       "subtype       subdural  \n",
       "id                      \n",
       "ID_000000e27       0.5  \n",
       "ID_000009146       0.5  \n",
       "ID_00007b8cb       0.5  \n",
       "ID_000134952       0.5  \n",
       "ID_000176f2a       0.5  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = make_usable_df(test_meta_df)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling Epidural Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    644870\n",
       "1    107933\n",
       "Name: any, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['any'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "any_df = train_df[train_df['any'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_oversampled = pd.concat([train_df, any_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df_oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (860736, 6)\n"
     ]
    }
   ],
   "source": [
    "print('Train Shape: {}'.format(train_df.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    644870\n",
       "1    215866\n",
       "Name: any, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['any'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/ Val Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Label Stratified Shuffel Splitter \n",
    "Cross Validaor with stratification on multiple labels:\n",
    "https://github.com/trent-b/iterative-stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_seed = 11\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=split_seed).split(np.arange(train_df.shape[0]), train_df[\"any\"].values)\n",
    "\n",
    "train_idx, val_idx = next(kfold)\n",
    "\n",
    "# train_data = traindf.iloc[train_idx]\n",
    "# dev_data = traindf.iloc[dev_idx]\n",
    "\n",
    "# #train_data, dev_data = train_test_split(traindf, test_size=0.1, stratify=traindf.values, random_state=split_seed)\n",
    "# print(train_data.shape)\n",
    "# print(dev_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(688588,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172148,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_idx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loan Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_multilabel_loss(y_true, y_pred, class_weights=None):\n",
    "    y_pred = np.where(y_pred > 1-(1e-07), 1-1e-07, y_pred)\n",
    "    y_pred = np.where(y_pred < 1e-07, 1e-07, y_pred)\n",
    "    single_class_cross_entropies = - np.mean(y_true * np.log(y_pred) + (1-y_true) * np.log(1-y_pred), axis=0)\n",
    "    \n",
    "    print(single_class_cross_entropies)\n",
    "    if class_weights is None:\n",
    "        loss = np.mean(single_class_cross_entropies)\n",
    "    else:\n",
    "        loss = np.sum(class_weights*single_class_cross_entropies)\n",
    "    return loss\n",
    "\n",
    "def get_raw_xentropies(y_true, y_pred):\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-7, 1-1e-7)\n",
    "    xentropies = y_true * K.log(y_pred) + (1-y_true) * K.log(1-y_pred)\n",
    "    return -xentropies\n",
    "\n",
    "# multilabel focal loss equals multilabel loss in case of alpha=0.5 and gamma=0 \n",
    "def multilabel_focal_loss(class_weights=None, alpha=0.5, gamma=2):\n",
    "    def mutlilabel_focal_loss_inner(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "        \n",
    "        xentropies = get_raw_xentropies(y_true, y_pred)\n",
    "\n",
    "        # compute pred_t:\n",
    "        y_t = tf.where(tf.equal(y_true,1), y_pred, 1.-y_pred)\n",
    "        alpha_t = tf.where(tf.equal(y_true, 1), alpha * tf.ones_like(y_true), (1-alpha) * tf.ones_like(y_true))\n",
    "\n",
    "        # compute focal loss contributions\n",
    "        focal_loss_contributions =  tf.multiply(tf.multiply(tf.pow(1-y_t, gamma), xentropies), alpha_t) \n",
    "\n",
    "        # our focal loss contributions have shape (n_samples, s_classes), we need to reduce with mean over samples:\n",
    "        focal_loss_per_class = tf.reduce_mean(focal_loss_contributions, axis=0)\n",
    "\n",
    "        # compute the overall loss if class weights are None (equally weighted):\n",
    "        if class_weights is None:\n",
    "            focal_loss_result = tf.reduce_mean(focal_loss_per_class)\n",
    "        else:\n",
    "            # weight the single class losses and compute the overall loss\n",
    "            weights = tf.constant(class_weights, dtype=tf.float32)\n",
    "            focal_loss_result = tf.reduce_sum(tf.multiply(weights, focal_loss_per_class))\n",
    "            \n",
    "        return focal_loss_result\n",
    "    return mutlilabel_focal_loss_inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    #K.clear_session()\n",
    "    \n",
    "    base_model = VGG19(weights = \"imagenet\", include_top=False, input_shape = SHAPE)\n",
    "    #base_model.load_weights(filepath+'model.h5')\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(100, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    y_pred = Dense(6, activation=\"sigmoid\")(x)\n",
    "\n",
    "    return Model(inputs = base_model.input, outputs = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "167/168 [============================>.] - ETA: 8s - loss: 0.3919 - accuracy: 0.8822 \n",
      "Epoch 00001: val_loss improved from inf to 0.29502, saving model to ../models/mymodels/vgg19_model3.h5\n",
      "168/168 [==============================] - 3660s 22s/step - loss: 0.3916 - accuracy: 0.8823 - val_loss: 0.2950 - val_accuracy: 0.9008\n",
      "Epoch 2/50\n",
      "167/168 [============================>.] - ETA: 1s - loss: 0.3258 - accuracy: 0.8981\n",
      "Epoch 00002: val_loss did not improve from 0.29502\n",
      "168/168 [==============================] - 1867s 11s/step - loss: 0.3258 - accuracy: 0.8980 - val_loss: 0.2970 - val_accuracy: 0.9008\n",
      "Epoch 3/50\n",
      " 25/168 [===>..........................] - ETA: 3:41 - loss: 0.3205 - accuracy: 0.8958"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Keras_worker_ForkPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nvidia/conda/envs/nvidia-dsd-1.3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/nvidia/conda/envs/nvidia-dsd-1.3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/nvidia/conda/envs/nvidia-dsd-1.3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/nvidia/conda/envs/nvidia-dsd-1.3/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/nvidia/conda/envs/nvidia-dsd-1.3/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/nvidia/conda/envs/nvidia-dsd-1.3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/nvidia/conda/envs/nvidia-dsd-1.3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-06e5da5c343c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m                         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                         \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                          use_multiprocessing = True)\n\u001b[0m",
      "\u001b[0;32m~/conda/envs/nvidia-dsd-1.3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/conda/envs/nvidia-dsd-1.3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/nvidia-dsd-1.3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[0;32m~/conda/envs/nvidia-dsd-1.3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/nvidia-dsd-1.3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/nvidia-dsd-1.3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n\u001b[1;32m    271\u001b[0m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unscaled_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         logging.warning('The list of trainable weights is empty. Make sure that'\n",
      "\u001b[0;32m~/conda/envs/nvidia-dsd-1.3/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    439\u001b[0m           \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distributed_apply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m           kwargs={\"name\": name})\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_distributed_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/nvidia-dsd-1.3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1915\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/nvidia-dsd-1.3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1922\u001b[0m         distribution_strategy_context._CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\n\u001b[1;32m   1923\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1924\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1925\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m       \u001b[0m_pop_per_thread_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/nvidia-dsd-1.3/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, name, apply_state)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/nvidia-dsd-1.3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign_add\u001b[0;34m(self, delta, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    779\u001b[0m       assign_add_op = gen_resource_variable_ops.assign_add_variable_op(\n\u001b[1;32m    780\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m    782\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_add_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/nvidia-dsd-1.3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36massign_add_variable_op\u001b[0;34m(resource, value, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;34m\"AssignAddVariableOp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         value)\n\u001b[0m\u001b[1;32m     53\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Create Data Generators for Train and Valid\n",
    "data_generator_train = TrainDataGenerator(train_df.iloc[train_idx], \n",
    "                                            train_df.iloc[train_idx], \n",
    "                                            TRAIN_BATCH_SIZE, \n",
    "                                            SHAPE,\n",
    "                                            augment = True)\n",
    "data_generator_val = TrainDataGenerator(train_df.iloc[val_idx], \n",
    "                                        train_df.iloc[val_idx], \n",
    "                                        VALID_BATCH_SIZE, \n",
    "                                        SHAPE,\n",
    "                                        augment = False)\n",
    "\n",
    "TRAIN_STEPS = int(len(data_generator_train) / TRAIN_BATCH_SIZE)\n",
    "\n",
    "#Adding custom Layers \n",
    "\n",
    "\n",
    "\n",
    "vgg19_model = create_model()\n",
    "\n",
    "for layer in vgg19_model.layers[:5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "\n",
    "my_callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "             ModelCheckpoint(filepath='../models/mymodels/vgg19_model3.h5', monitor='val_loss', save_best_only=True, verbose=1)]\n",
    "\n",
    "\n",
    "# compile the model \n",
    "vgg19_model.compile(loss = 'binary_crossentropy', optimizer = \"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train the model \n",
    "history = vgg19_model.fit_generator(generator = data_generator_train,\n",
    "                        validation_data = data_generator_val,\n",
    "                        steps_per_epoch = TRAIN_STEPS,\n",
    "                        epochs = 50,\n",
    "                        callbacks = my_callbacks,\n",
    "                        verbose = 1,\n",
    "                         use_multiprocessing = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               51300     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 20,076,290\n",
      "Trainable params: 19,963,714\n",
      "Non-trainable params: 112,576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg19_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtgAAAHwCAYAAACcxBjDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd5iU1fnG8fsBpAsoRQWkCgzEFkUFNUaJGgtgiQVFLFGjRqOJib1EY49R7IVYAEURFZUoFhSxYQNFUBGki6ICUpW2cH5/PLM/Rtxddth5553y/VzXXsu8M/POs7PL7j1nznmOhRAEAAAAIDOqxV0AAAAAUEgI2AAAAEAGEbABAACADCJgAwAAABlEwAYAAAAyiIANAAAAZBABG0BszKy6mS03s1aZvG2czGw7M4uk/+mG5zazV8ysbxR1mNkVZnbfpt4/F5nZXDPbN+46NoWZnWZmY+KuA0DlELABVFoy4JZ+rDOzFSmXywx6FQkhrA0h1A8hzMnkbXOVmb1mZleWcfwPZva1maX1OzmEcGAIYUgG6trfzGZtcO5rQghnVvXcZTxW3gfF5PO1boP/D8vNbLe4awOQGwjYACotGXDrhxDqS5ojqVfKsV8EPTOrkf0qc9pASf3KON5P0qMhhHXZLQdVMCf1/0Py48O4iwKQGwjYADLGzK41syfM7HEzWybpBDPrbmbvmdliM5tnZneY2WbJ29cws2BmbZKXH01e/6KZLTOzd82sbbq3TV5/sJlNNbMlZnanmb1jZieXU3dlajzDzKaZ2SIzuyPlvtXNrL+ZLTSz6ZIOquApGi5pazPbM+X+jSUdImlw8nJvM5uQ/JrmmNkVFTzfb5d+TRurIzlyPDl53ulmdlryeENJ/5PUKmUktlnyezkw5f6Hm9lnyedotJl1Srlurpmdb2aTks/342ZWq4Lnobyvp6WZPW9mP5jZl2b2x5TrupnZR2a21My+M7Obk8frmtljya97sZl9YGZNKniYPZLPwyIze7C0TjP7wswOTnm8WsnbbL8JX8fbZnadmY1LPh/PmNkWKddX9Fy2NrNnzWy+mS0ws9t/fmrrn7zfDDM7MOWKU81sVvL7O8PM+qRbN4DMIWADyLQjJD0mqaGkJySVSDpPUhNJe8mD3xkV3P94SVdI2lI+Sn5Nurc1s2aShkm6IPm4MyXtXsF5KlPjIZJ2lfRr+QuH/ZPHz5J0oKSdko9xTHkPEkL4UdJTkk5MOdxH0sQQwmfJy8slnSB//npJOs/MelZQe6mN1fGdpEMlNZB0uqQ7zWzHEMKS5OOkjsh+n3pHM+ss6VFJf5HUVNKrkv5X+iIk6RhJB0hqJ3+eyhqp35gn5N+r5pKOlfRvM/tt8ro7Jd0cQmggaTv58yhJp0iqK6mlpMaS/ixpZQWP0TdZZwdJv5J0SfL4YPnzXqqnpFkhhE834euQ/Ht8YvJrMUn9pYqfS/N3fF6QNE1SG0nbyn+OS+0paVLy6+wv6cHkORtIulXSASGEzeU/wxM3sW4AGUDABpBpb4cQ/hdCWBdCWBFC+DCE8H4IoSSEMEPSAEm/reD+T4UQxoUQ1kgaImnnTbhtT0kTQgjPJa/rL2lBeSepZI03hBCWhBBmSRqT8ljHSOofQpgbQlgo6cYK6pWkQZKOSRnhPTF5rLSW0SGET5PP3yeShpZRS1kqrCP5PZkR3GhJr0n6TSXOK/mLgBHJ2tYkz91A0h4pt7kthPBt8rGfV8Xft19Ivvuwu6SLQwgrQwgfSXpY64P6GkkdzKxxCGFZCOH9lONNJG2XnKc/LoSwvIKHuiP5HC2QdL2k45LHH5HUy8zqJy/3Sx4rT6vkSHLqR+qo/aAQwufJF1VXSupjZqaKn8vuya/lohDCj8n/P++knHN6COGhEMJa+c9My5TR+iBpezOrHUKYF0L4vILaAUSMgA0g075KvWBmCTN7wcy+NbOlkv4lDxHl+Tbl3z9Jql/eDSu4bfPUOkIIQdLc8k5SyRor9ViSZldQryS9IWmJPMx1lI+IP55SS3czG5OcIrBE0mll1FKWCusws55m9n5y+sVi+Wh3Zc5beu7/P19yrvhcSS1SbpPO9628x1iQDKSlZqc8ximSukiakpwGckjy+ED5KPAw84WiN1rFc/83fI6aS1II4StJH0g6wsy2lD8/j1VwnjkhhEYbfKyq4HFqyd9pqei53FY+ar62nMfc8DmWpPohhKXyFwpnS/o2Oc2mYwW1A4gYARtApm3YGu5+SZ/KRxgbyEfzLOIa5smnDEjyiav6eRjcUFVqnCcPRqUqbCOYDPuPyEeu+0kamRxNLTVU0tOStg0hNJT0QCVrKbcOM6sjn1Jxg6StQgiNJL2Sct6NtfP7RlLrlPNVkz+/X1eirsr6RlITM6uXcqxV6WOEEKaEEPpIaibpFklPJ0drV4cQrgohdJa0t3yKUkUdbTZ8jr5JuTxIPk3kWElvhhBSA226NnycVZJ+UMXP5VeSWptZ9XQfLITwYghhf0nbyKeY3L/ppQOoKgI2gKhtLh+x/TE5/7Si+deZ8rykXcysV3I08zz5fNcoahwm6a9m1sJ8weJFlbjPIPk87z8qZXpISi0/hBBWmlk3+ZSCqtZRS1JNSfMlrU3O6f5dyvXfycPt5hWcu7eZ7Zucd32BpGWS3i/n9htTzcxqp36EEGZKGifp+uQCw53lo9ZDJMnM+plZk+SI7xL5i4J1ZtbDzLZPBtWl8ikj5Y0AS9I5Kc/RJfJ536WGy6dqnKPkotMqODH5zkg9SVdLGpZ8cVXRc/mupIXJ56CumdUxs7029kBmtk3yZ72upNWSflTFzwGAiBGwAUTt75JOkoeI+/XzQBOJEMJ38lHIW+WBpb2kj+WjiJmu8V75fOZJkj7U+sV3FdU3XT4dobZ8UVuqsyTdYN6F5VL9fJHbJtURQlgs6W+SnpGPoh4lfxFSev2n8lHzWcm5xM02qPcz+fNzrzykHySpd3IO8ab4jaQVG3xI/j3rIJ8K8ZSkS0MIryevO0TS5OTz8h9Jx4YQVsunXAyXh+vP5NNF/n/KTRkeT95muqQp8nnYpV/nj5KelY84P7uRryG160rpx+Ep1z8iX8w4T1J1SX9NPka5z2UIoUS+fqCzfDR7jvx7tTHV5UF9nvznfU/5iwQAMTF/QQ0AhSv5lvs3ko4KIbwVdz3IXWb2L0mtQggnV+Ecb0t6IIQwMFN1AcgvjGADKEhmdpCZNUx2drhC3orvg5jLQg5LThs5Rd5FBgA2GQEbQKHaW9IMeXu+gyQdvkGXB+D/mdlZ8ikZz4UQxsZdD4D8xhQRAAAAIIMYwQYAAAAyiIANAAAAZFBFu13lnSZNmoQ2bdrEXQYAAAAK3Pjx4xeEEMrcY6GgAnabNm00bty4uMsAAABAgTOz2eVdxxQRAAAAIIMI2AAAAEAGEbABAACADCJgAwAAABlEwAYAAAAyiIANAAAAZBABGwAAAMggAjYAAACQQQRsAAAAIIMI2AAAAEAGEbABAACADCJgAwAAABlEwAYAAAAyiIANAAAAZBABGwAAAMggAjYAAACQQQTsDFi9Wlq4MO4qAAAAkAsI2BnQpYt07rlxVwEAAIBcQMDOgA4dpC++iLsKAAAA5AICdgYkEh6w162LuxIAAADEjYCdAYmE9NNP0tdfx10JAAAA4kbAzoBEwj8zTQQAAAAE7AwgYAMAAKAUATsDmjWTGjUiYAMAAICAnRFmPoo9eXLclQAAACBuBOwMKe0kAgAAgOJGwM6QREKaN09asiTuSgAAABAnAnaGlC50nDIl3joAAAAQLwJ2htBJBAAAABIBO2PatZNq1CBgAwAAFDsCdoZstpm03XYEbAAAgGJHwM6gzp0J2AAAAMWOgJ1BiYQ0bZq0Zk3clQAAACAuBOwMSiQ8XM+cGXclAAAAiAsBO4PoJAIAAAACdgZ16uSfCdgAAADFi4CdQQ0bSttsQ8AGAAAoZgTsDEskCNgAAADFjICdYaUBO4S4KwEAAEAcCNgZlkhIixZJ8+fHXQkAAADiQMDOMDqJAAAAFDcCdoYRsAEAAIobATvDWraU6tYlYAMAABQrAnaGVavm/bAJ2AAAAMWJgB0BWvUBAAAULwJ2BBIJadYsacWKuCsBAABAthGwI5BIeB/sL7+MuxIAAABkGwE7AnQSAQAAKF4E7Ah06CCZEbABAACKEQE7AnXqSG3aELABAACKEQE7IomENHly3FUAAAAg2wjYEUkkpClTpHXr4q4EAAAA2UTAjkgi4W36vvoq7koAAACQTQTsiNBJBAAAoDgRsCNCwAYAAChOBOyING0qbbEFARsAAKDYELAjYuaj2ARsAACA4kLAjhABGwAAoPgQsCPUubP07bfS4sVxVwIAAIBsIWBHqHSh45Qp8dYBAACA7CFgR4hOIgAAAMWHgB2htm2lzTYjYAMAABQTAnaEatSQOnQgYAMAABSTyAO2mR1kZlPMbJqZXVzG9X3NbGLyY6yZ7ZRy3d/M7DMz+9TMHjez2lHXm2l0EgEAACgukQZsM6su6W5JB0vqIuk4M+uywc1mSvptCGFHSddIGpC8bwtJ50rqGkLYXlJ1SX2irDcKiYQ0bZq0Zk3clQAAACAboh7B3l3StBDCjBDCaklDJR2WeoMQwtgQwqLkxfcktUy5uoakOmZWQ1JdSd9EXG/GJRJSSYk0Y0bclQAAACAbog7YLSR9lXJ5bvJYeU6V9KIkhRC+lvQfSXMkzZO0JITwSkR1RoZOIgAAAMUl6oBtZRwLZd7QbD95wL4oeXkL+Wh3W0nNJdUzsxPKuN+fzGycmY2bP39+xgrPlE6d/DMBGwAAoDhEHbDnSto25XJLlTHNw8x2lPSApMNCCAuTh/eXNDOEMD+EsEbScEl7bnjfEMKAEELXEELXpk2bZvwLqKoGDaTmzQnYAAAAxSLqgP2hpA5m1tbMasoXKY5IvYGZtZKH534hhKkpV82R1M3M6pqZSfqdpMkR1xsJOokAAAAUj0gDdgihRNI5kl6Wh+NhIYTPzOxMMzszebMrJTWWdI+ZTTCzccn7vi/pKUkfSZqUrHVAlPVGpTRghzInxwAAAKCQ1Ij6AUIIIyWN3ODYfSn/Pk3SaeXc95+S/hlpgVmQSEiLF0vffy9ttVXc1QAAACBK7OSYBXQSAQAAKB4E7CwgYAMAABQPAnYWtGgh1atHwAYAACgGBOwsqFbN+2ETsAEAAAofATtLEglpcl42GQQAAEA6CNhZkkhIs2dLP/0UdyUAAACIEgE7S0oXOk6dWvHtAAAAkN8I2FlCJxEAAIDiQMDOkg4dJDMCNgAAQKEjYGdJ7dpS27YEbAAAgEJHwM6iRIKADQAAUOgI2FmUSEhTpkjr1sVdCQAAAKJCwM6izp2llSulOXPirgQAAABRIWBnEZ1EAAAACh8BO4sI2AAAAIWPgJ1FTZpIjRsTsAEAAAoZATvL6CQCAABQ2AjYWUbABgAAKGwE7CxLJKTvvpMWLYq7EgAAAESBgJ1lpQsdp0yJtw4AAABEg4CdZXQSAQAAKGwE7Cxr00aqWZOADQAAUKgI2FlWo4bUoQMBGwAAoFARsGNAJxEAAIDCRcCOQSIhTZ8urVkTdyUAAADINAJ2DBIJqaTEQzYAAAAKCwE7BnQSAQAAKFwE7Bh06uSfCdgAAACFh4Adg803l1q0IGADAAAUIgJ2TOgkAgAAUJgI2DFJJKTJk6UQ4q4EAAAAmUTAjkkiIS1dKn37bdyVAAAAIJMI2DGhkwgAAEBhImDHhIANAABQmAjYMWnRQqpXj4ANAABQaAjYMTGjkwgAAEAhImDHiIANAABQeAjYMUokpDlzpB9/jLsSAAAAZAoBO0alCx2nTo23DgAAAGQOATtGnTv7Z6aJAAAAFA4Cdoy2206qVo2ADQAAUEgI2DGqVUtq146ADQAAUEgI2DGjkwgAAEBhIWDHLJHwRY5r18ZdCQAAADKBgB2zREJaudLb9QEAACD/EbBjVtqqj2kiAAAAhYGAHTMCNgAAQGEhYMescWOpSRMCNgAAQKEgYOcAOokAAAAUDgJ2DiBgAwAAFA4Cdg5IJKTvv5d++CHuSgAAAFBVBOwcULrQccqUeOsAAABA1RGwcwCdRAAAAAoHATsHtGkj1axJwAYAACgEBOwcUL261LEjARsAAKAQELBzBJ1EAAAACgMBO0ckEtL06dLq1XFXAgAAgKogYOeIREJau1aaNi3uSgAAAFAVBOwcQScRAACAwkDAzhGdOvlnAjYAAEB+I2DniPr1pZYtCdgAAAD5joCdQ+gkAgAAkP8I2DmkNGCHEHclAAAA2FQE7BySSEjLlknz5sVdCQAAADYVATuH0EkEAAAg/xGwcwgBGwAAIP8RsHNI8+bS5psTsAEAAPIZATuHmNFJBAAAIN8RsHMMARsAACC/EbBzTCIhffWVtHx53JUAAABgUxCwc0zpQsepU+OtAwAAAJuGgJ1j6CQCAACQ3wjYOaZ9e6l6dQI2AABAviJg55hataR27QjYAAAA+YqAnYPoJAIAAJC/CNg5KJHwRY5r18ZdCQAAANJFwM5BiYS0apU0e3bclQAAACBdBOwcRCcRAACA/EXAzkGdOvlnAjYAAED+iTxgm9lBZjbFzKaZ2cVlXN/XzCYmP8aa2U4p1zUys6fM7Aszm2xm3aOuNxc0biw1bUrABgAAyEc1ojy5mVWXdLekAyTNlfShmY0IIXyecrOZkn4bQlhkZgdLGiBpj+R1t0t6KYRwlJnVlFQ3ynpzCZ1EAAAA8lPUI9i7S5oWQpgRQlgtaaikw1JvEEIYG0JYlLz4nqSWkmRmDSTtI+nB5O1WhxAWR1xvziBgAwAA5KeoA3YLSV+lXJ6bPFaeUyW9mPx3O0nzJT1sZh+b2QNmVi+aMnNPIiHNny8tXBh3JQAAAEhH1AHbyjgWyryh2X7ygH1R8lANSbtIujeE8GtJP0oqaw73n8xsnJmNmz9/fmaqzgF0EgEAAMhPUQfsuZK2TbncUtI3G97IzHaU9ICkw0IIC1PuOzeE8H7y8lPywP0zIYQBIYSuIYSuTZs2zWjxcSJgAwAA5KeoA/aHkjqYWdvkIsU+kkak3sDMWkkaLqlfCGFq6fEQwreSvjKzZNM6/U5S6uLIgta6tVSrFgEbAAAg30TaRSSEUGJm50h6WVJ1SQ+FED4zszOT198n6UpJjSXdY2aSVBJC6Jo8xV8kDUmG8xmSTomy3lxSvbrUsSMBGwAAIN9EGrAlKYQwUtLIDY7dl/Lv0ySdVs59J0jqWtZ1xSCRkD7+OO4qAAAAkA52csxhiYQ0Y4a0alXclQAAAKCyCNg5LJGQ1q2Tpk2LuxIAAABUFgE7h9FJBAAAIP8QsHNYx47+mYANAACQPwjYOax+fWnbbQnYAAAA+YSAneM6dyZgAwAA5BMCdo5LJDxghzI3mAcAAECuIWDnuERCWr5c+uYXG8wDAAAgFxGwcxydRAAAAPILATvHEbABAADyCwE7x229tdSgAQEbAAAgXxCwc5zZ+oWOAAAAyH2VDthmVs/MqiX/3dHMepvZZtGVhlIEbAAAgPyRzgj2m5Jqm1kLSa9JOkXSwCiKws8lEtLcudKyZXFXAgAAgI1JJ2BbCOEnSUdKujOEcISkLtGUhVSlCx2nTo23DgAAAGxcWgHbzLpL6ivpheSxGpkvCRuikwgAAED+SCdg/1XSJZKeCSF8ZmbtJL0eTVlI1b69VL06ARsAACAfVHoEOoTwhqQ3JCm52HFBCOHcqArDejVresgmYAMAAOS+dLqIPGZmDcysnqTPJU0xswuiKw2p6CQCAACQH9KZItIlhLBU0uGSRkpqJalfJFXhFxIJX+S4dm3clQAAAKAi6QTszZJ9rw+X9FwIYY2kEE1Z2FAiIa1eLc2cGXclAAAAqEg6Aft+SbMk1ZP0ppm1lrQ0iqLwS3QSAQAAyA+VDtghhDtCCC1CCIcEN1vSfhHWhhSdOvlnAjYAAEBuS2eRY0Mzu9XMxiU/bpGPZiMLttxSataMgA0AAJDr0pki8pCkZZKOSX4slfRwFEWhbHQSAQAAyH3p7MTYPoTwh5TLV5vZhEwXhPIlEtLTT8ddBQAAACqSzgj2CjPbu/SCme0laUXmS0J5Eglp4UJpwYK4KwEAAEB50hnBPkvSIDNrKMkk/SDp5CiKQtlSO4nsvXfFtwUAAEA80tkqfYKkncysQfIyLfqyjIANAACQ+zYasM3s/HKOS5JCCLdmuCaUo1UrqXZtFjoCAADkssqMYG8eeRWolOrVpY4dCdgAAAC5bKMBO4RwdWVOZGaXhBBuqHpJqEgiIY0fH3cVAAAAKE86XUQ25ugMngvl6NxZmjlTWrky7koAAABQlkwGbMvguVCOREJat06aNi3uSgAAAFCWTAbskMFzoRypnUQAAACQexjBzjMdO/pnAjYAAEBuymTAfjKD50I56taVWrcmYAMAAOSqSm80Y2Z3lHF4iaRxIYTnQgjXZ64sVCSRIGADAADkqnRGsGtL2lnSl8mPHSVtKelUM7stgtpQjtKAHZj1DgAAkHMqPYItaTtJPUIIJZJkZvdKekXSAZImRVAbypFISD/+KH39tdSyZdzVAAAAIFU6I9gtJNVLuVxPUvMQwlpJqzJaFSpEJxEAAIDclU7A/rekCWb2sJkNlPSxpP+YWT1Jr0ZRHMpGwAYAAMhdlZ4iEkJ40MxGStpd3pLv0hDCN8mrL4iiOJRtq62khg0J2AAAALkonTnYkrSbpN8k/71W0jcV3BYRMaOTCAAAQK6q9BQRM7tR0nmSPk9+nGtmN0RVGCpGwAYAAMhN6czBPkTSASGEh0IID0k6SNKh0ZSFjUkkvIvIsmVxVwIAAIBU6e7k2Cjl3w0zWQjSw0JHAACA3JTOHOwbJH1sZq/LFznuI+mSSKrCRqUG7N12i7cWAAAArJdOF5HHzWyMfKGjSboohPBtVIWhYu3bSzVqMIINAACQazYasM1slw0OzU1+bm5mzUMIH2W+LGzMZpt5yCZgAwAA5JbKjGDfUsF1QVKPDNWCNNFJBAAAIPdsNGCHEParzInM7IAQwqiql4TKSiSkkSOlkhKfLgIAAID4pdtFpCI3ZfBcqIREQlqzRpo5M+5KAAAAUCqTAdsyeC5UAq36AAAAck8mA3bI4LlQCZ06+WcCNgAAQO7IZMBGlm2xhbTVVgRsAACAXJLJgD0rg+dCJdFJBAAAILdUpg/2kRVdH0IYnvxc4e0QjURCGjZMCkEyZsEDAADErjLN3XolPzeTtKek0cnL+0kaI2l45stCZXXuLC1aJC1YIDVtGnc1AAAAqEwf7FMkycyel9QlhDAveXkbSXdHWx42JrWTCAEbAAAgfunMwW5TGq6TvpPUMcP1IE206gMAAMgt6ez/N8bMXpb0uLwlXx9Jr0dSFSpt222lOnUI2AAAALmi0gE7hHCOmR0haZ/koQEhhGeiKQuVVa2a98MmYAMAAOSGdEawJekjSctCCK+aWV0z2zyEsCyKwlB5iYT0wQdxVwEAAAApjTnYZna6pKck3Z881ELSs1EUhfQkEtLMmdLKlXFXAgAAgHQWOZ4taS9JSyUphPClvHUfYpZIeB/sL7+MuxIAAACkE7BXhRBWl14wsxryxY6IGZ1EAAAAckc6AfsNM7tUUh0zO0DSk5L+F01ZSEeHDr6LIwEbAAAgfukE7IslzZc0SdIZkkaGEC6LpCqkpW5dqXVrAjYAAEAuSKeLyF9CCLdL+m/pATM7L3kMMUskCNgAAAC5IJ0R7JPKOHZyhupAFZUG7HXr4q4EAACguG10BNvMjpN0vKS2ZjYi5arNJS2MqjCkJ5GQfvpJ+vpr390RAAAA8ajMFJGxkuZJaiLplpTjyyRNjKIopK+0k8jkyQRsAACAOG00YIcQZkuaLal79OVgU6W26jvwwHhrAQAAKGbp7OR4pJl9aWZLzGypmS0zs6VRFofKa9ZMatSIhY4AAABxS6eLyL8l9QohTI6qGGw6MzqJAAAA5IJ0uoh8R7jObQRsAACA+FWmi8iRyX+OM7MnJD0raVXp9SGE4RHVhjQlEtLAgdKSJVLDhnFXAwAAUJwqM4LdK/nRQNJPkg5MOdZzY3c2s4PMbIqZTTOzi8u4vq+ZTUx+jDWznTa4vrqZfWxmz1fmCypmpQsdp0yJtw4AAIBiVpkuIqds6snNrLqkuyUdIGmupA/NbEQI4fOUm82U9NsQwiIzO1jSAEl7pFx/nqTJ8oCPCqR2Etl993hrAQAAKFaVXuRoZneUcXiJpHEhhOfKudvukqaFEGYkzzFU0mGS/j9ghxDGptz+PUktUx6zpaRDJV0n6fzK1lqs2rWTatRgHjYAAECc0lnkWFvSzpK+TH7sKGlLSaea2W3l3KeFpK9SLs9NHivPqZJeTLl8m6QLJbEBeCVstpm03XYEbAAAgDil06ZvO0k9QgglkmRm90p6RT79Y1I597EyjoUyb2i2nzxg75283FPS9yGE8Wa2b3lFmdmfJP1Jklq1alWpL6SQ0UkEAAAgXumMYLeQVC/lcj1JzUMIa5XSVWQDcyWlbtzdUtI3G97IzHaU9ICkw0IIC5OH95LU28xmSRoqqYeZPbrhfUMIA0IIXUMIXZs2bZrGl1OYEglp2jRpzZq4KwEAAChO6QTsf0uaYGYPm9lASR9L+o+Z1ZP0ajn3+VBSBzNra2Y1JfWRNCL1BmbWStJwSf1CCFNLj4cQLgkhtAwhtEneb3QI4YQ06i1KiYSH65kz464EAACgOFV6ikgI4UEzGylfuGiSLg0hlI5GX1DOfUrM7BxJL0uqLumhEMJnZnZm8vr7JF0pqbGke8xMkkpCCF039Qsqdp07++cvvpA6doy3FgAAgGJkIZQ5JXr9DcwSIYQvzGyXsq4PIXwUSWWboGvXrmHcuHFxlxGrJUukRo2km26SLrww7moAAAAKk5mNL29QuDIj2OfLFxHeUsZ1QVKPKtSGDGvYUNpmGxY6AgAAxKUyG838Kfl5v+jLQSbQSQQAACA+lV7kaGZ1zexyMxuQvNwh2UoPOaY0YG9k9g8AAAAikE4XkYclrZa0Z/LyXEnXZrwiVFkiIS1aJM2fH+nDi6QAACAASURBVHclAAAAxSedgN0+hPBvSWskKYSwQmVvJIOYJRL+mWkiAAAA2ZdOwF5tZnWU3InRzNqr/A1mECMCNgAAQHzS2Sr9n5JekrStmQ2R77R4chRFoWpatpTq1iVgAwAAxCGdgH2ipBckPSVphqTzQggLIqkKVVKtmtSpEwEbAAAgDukucqwtqbekOyTdb2bnRVIVqoxWfQAAAPGodMAOIYyWdJ2kKyQ9IKmrpLMiqgtVlEhIs2ZJK1bEXQkAAEBxSacP9muS3pF0rKQpknYLISSiKgxVk0h4H+wvv4y7EgAAgOKSzhSRifI+2NtL2lHS9smuIshBpZ1EJk+Otw4AAIBiU+lFjiGEv0mSmdWXdIp8TvbWkmpFUxqqokMHyYx52AAAANlW6YBtZudI+o2kXSXNlvSQpLciqgtVVKeO1KYNARsAACDb0mnTV0fSrZLGhxBKIqoHGUQnEQAAgOxLZ4rIzVEWgsxLJKQxY6R167w3NgAAAKJH7CpgiYS36fvqq7grAQAAKB4E7AJW2kmEaSIAAADZQ8AuYARsAACA7CNgF7CmTaUttiBgAwAAZBMBu4CZ0UkEAAAg2wjYBY6ADQAAkF0E7AKXSEjffistXhx3JQAAAMWBgF3gShc6TpkSbx0AAADFgoBd4OgkAgAAkF0E7ALXrp202WYEbAAAgGwhYBe4GjWkDh0I2AAAANlCwC4CdBIBAADIHgJ2EUgkpGnTpDVr4q4EAACg8BGwi0AiIZWUSF9+GXclAAAAhY+AXQT23FOqWVP685+l1avjrgYAAKCwEbCLQPv20kMPSW+8IZ15phRC3BUBAAAUrhpxF4Ds6NtXmjpV+te/pE6dpIsuirsiAACAwkTALiJXXeUh++KLvXXfkUfGXREAAEDhYYpIETGTHn5Y6tZNOuEEady4uCsCAAAoPATsIlO7tvTss1KzZlLv3tLcuXFXBAAAUFgI2EVoq62k55+Xli+XevXyzwAAAMgMAnaR2n57adgwaeJEXwC5dm3cFQEAABQGAnYRO+gg6fbbpREj6CoCAACQKXQRKXLnnCN98YV0yy3evu/00+OuCAAAIL8RsKHbbpOmT/edHtu1k373u7grAgAAyF9MEYFq1JCGDvUR7KOO8hFtAAAAbBoCNiRJDRt6Z5HNNpN69pQWLIi7IgAAgPxEwMb/a9NGeu4574195JHSqlVxVwQAAJB/CNj4me7dfbfHt96SzjhDCiHuigAAAPILixzxC8cdJ02dKl11lc/LvuSSuCsCAADIHwRslOnKK6UpU6RLL5U6dPDFjwAAANg4poigTGbSQw/5lJF+/aQPP4y7IgAAgPxAwEa5ateWnn1W2nprqXdvac6cuCsCAADIfQRsVKhZM2/f99NPUq9e0rJlcVcEAACQ2wjY2Khf/UoaNkz69FPp+OOltWvjrggAACB3EbBRKb//vXTHHT6afcEFcVcDAACQu+gigko7+2zvLNK/v7fvO+OMuCsCAADIPQRspOXWW6Vp0zxst28v7b9/3BUBAADkFqaIIC01akhDh0qdO3tv7MmT464IAAAgtxCwkbYGDXwudq1aUs+e0oIFcVcEAACQOwjY2CStW0vPPSd9/bV0xBHSqlVxVwQAAJAbCNjYZN26SYMGSW+/LZ12mhRC3BUBAADEj0WOqJJjj5WmTpWuvFJKJKTLLou7IgAAgHgRsFFll1/u7fsuv1zq0EE65pi4KwIAAIgPU0RQZWbSAw9Ie+4pnXSS9P77cVcEAAAQHwI2MqJ2benZZ6VttpEOO0yaPTvuigAAAOJBwEbGNG3q7ftWrJB69ZKWLYu7IgAAgOwjYCOjunSRnnxS+vxz6bjjpLVr464IAAAguwjYyLgDD5TuvFN64QXp73+PuxoAAIDsImAjEmedJZ13nnT77dK998ZdTeELQbrwQn8HYf78uKsBAKC4EbARmVtukQ49VPrLX6RXXom7msIVgnT++dLNN0uTJ0unnsqmPwAAxImAjchUry49/riPqh59tM/LRmaFIF1wgXTbbdK550q33ir973/SgAFxVwYAQPEiYCNSm2/unUXq1JF69mT6QiaFIF18sb9TcM45HrLPO0864ADpb3+Tvvgi7goBAChOBGxErlUracQIad486fDDpZUr464o/4UgXXqp9O9/+3z3O+7wDX+qVZMGDpTq1pX69pVWr467UgAAig8BG1mx++7S4MHS2LHMEa6qEKQrrpBuvFE64wzprrs8XJdq3tx31vzoI+nKK+OrEwCAYkXARtYcfbR07bXSY4/5Z2yaq66SrrtOOu006Z57fNR6Q4cfLp1+uo9wjxmT7QoBAChuBGxk1aWXSv36+cjqE0/EXU3+ufpq6V//kv74R+n++8sO16X695c6dPDne9Gi7NUIAECxI2Ajq8yk//5X2ntv6aSTpPfei7ui/HHttT56ffLJ/hxWFK4lqV49acgQ6dtvpTPPZFoOAADZQsBG1tWqJT3zjNSihXTYYdKsWXFXlPtuuMHnXffr5/OrNxauS3Xt6iPew4ZJjzwSbY0AAMARsBGLJk28fd+qVVKvXtLSpXFXlLtuusmn1vTtKz38sPcXT8eFF0r77COdfbY0fXo0NQIAgPUI2IhN587SU0/57oN9+kglJXFXlHv+8x/vdX3ccd5+L91wLfl9Bg/2z/368TwDABA1AjZitf/+0t13Sy++6C3nVq2Ku6Lc0b+/79J47LEekGvU2PRztW4t3Xef9O673oEEAABEh4CN2J1xhk+BeOghqVs3tlSXpNtvl84/XzrqKOnRR6sWrkv16SOdcILPyX733aqfDwAAlC3ygG1mB5nZFDObZmYXl3F9XzObmPwYa2Y7JY9va2avm9lkM/vMzM6LulbE57rrpOeek+bOlXbd1TdPKdauF3feKf31r9KRR3rP8EyE61J33eU7a/bty7x3AACiEmnANrPqku6WdLCkLpKOM7MuG9xspqTfhhB2lHSNpAHJ4yWS/h5C6Cypm6Szy7gvCkjv3tKkSdK++0p/+Yt06KHeYq6Y3HOPdO65vlHM0KHSZptl9vwNG/qI+OzZ/jgAACDzoh7B3l3StBDCjBDCaklDJR2WeoMQwtgQQuk2GO9Japk8Pi+E8FHy38skTZbUIuJ6EbOtt5ZGjvRR3Ndfl3bYQfrf/+KuKjvuu887ffTu7ZvwZDpcl9prL+myy6RBg7x9HwAAyKyoA3YLSV+lXJ6rikPyqZJe3PCgmbWR9GtJ72ewNuQoM+mcc6Tx471Xdu/evlHKjz/GXVl0BgyQzjpL6tlTevJJqWbNaB/viiukPfbw+e9ffbXx2wMAgMqLOmBbGcfKnFlrZvvJA/ZFGxyvL+lpSX8NIfxi1qiZ/cnMxpnZuPnz52egZOSKLl2k99+X/vEPD6C77CKNGxd3VZn34IMedA85xNsWRh2uJR8df/RRac0a6cQTpbVro39MAJU3Zow0b17cVQDYVFEH7LmStk253FLSNxveyMx2lPSApMNCCAtTjm8mD9dDQgjDy3qAEMKAEELXEELXpk2bZrR4xK9WLenmm6VXX5V++knq3l26/vrCCYQPPyydfrp00EHS00/715st223nU3HGjJFuuSV7jwugYgMGSPvtJyUS0r33SuvWxV0RgHRFHbA/lNTBzNqaWU1JfSSNSL2BmbWSNFxSvxDC1JTjJulBSZNDCLdGXCdyXI8e0sSJ3lnjssv8j8/s2XFXVTWDBkmnniodcIBvHV+7dvZrOPlk6Q9/kC6/XProo+w/PoCfe/ZZny52wAHSbrtJf/6zr5uYNCnuygCkI9KAHUIokXSOpJflixSHhRA+M7MzzezM5M2ulNRY0j1mNsHMSicB7CWpn6QeyeMTzOyQKOtFbttiC++sMWiQNGGCtOOO0pAhcVe1aR59VDrlFOl3v/M/qHGEa8nnuw8YIDVrJh1/vL9LACAeb7/tu7butpu/6B41yjeZmjbNp8hdcom0YkXcVQKoDAsF1Gy4a9euYVwhTtLFL8yc6ZumjB3rf5DuuUdq1Cjuqirnscd8y/J99/UOKXXrxl2R9NprvqvmmWf6W9IAsuuzz6S99/YXu++8IzVpsv66BQt8V9eBA6V27bzj0AEHxFYqgCQzGx9C6FrWdezkiLzUtq30xhvSNdd4q7mddvLLuW7oUA/X++yTO+Fa8pH0f/zD/3CPGLHx2wPInK++8nUYdepIL7/883At+eWHH5ZGj5aqV5cOPNAHGL7/Pp56AWwcARt5q0YNnzv8zjveeWO//fwt1NWr466sbMOG+R/FvfeWnn8+d8J1qWuvlXbe2eeFF9sGP0BcfvhB+v3vfWfVl16S2rQp/7b77edrUa680n+fJBLSQw8V7663QC4jYCPv7bGH9PHHHgxvvNE7jXzxRdxV/dxTT/kc5+7dpRdekOrVi7uiX6pVy6evLF/u88P5ow1Ea8UK7/M/fbr03HO+rmRjateWrr5a+uQTafvt/ffevvvm3u88oNgRsFEQ6teX/vtfafhw7y6yyy4+lzgXQuIzz/g88W7dfJfK+vXjrqh8nTt7y76XXpLuuivuaoDCVVIi9enj60iGDPGQnI7Onb3F5n//66PaO+0kXXWVtGpVBMUCSBsBGwXliCP8j81vfuPtrXr3jnee4nPPSccc410BRo6UNt88vloq66yzpEMP9UVVn34adzVA4QnBfz+NGOG96I86atPOU62adNppPnp91FE+sp0v61GAQkfARsFp3lx68UXp9tu9zdUOO/i0jGz73/+ko4+Wdt3V62nQIPs1bAoz312yYUOf1rJyZdwVAYXlqqt85Pmyy6Szz676+bbaykfBX3rJ16Dsu6/0xz9KCxdu9K4AIkLARkGqVk0691zfWn3rraWePf0PWbb6PL/wgm/gsvPO3hWgYcPsPG6mbLWVdy2YNEm69NK4qwEKx333Sf/6lwfga67J7Ll//3t/1+mii7x/dufO3nM/F6bKAcWGgI2Ctv320vvvS+ef772yd901+h0LX3zRd5zccUfplVfyL1yXOuQQf1HSv79/HQCqZvhwnxrSs6d0//3+blGm1a3ri70/+sh7Zvfr58F7+vTMPxaA8hGwUfBq1/aFe6NGeSusbt2km26S1q7N/GO9/LLPA99+e3+8fNn8pjw33+yjYCef7JtdANg0b77pU666dZOeeMLbjEZpxx29hendd/sgw/bbSzfcIK1ZE+3jAnAEbBSN/ff3BZC9e0sXX+ybq8yZk7nzjxolHXaYB9JRo3xr93xXp4637luwQDr9dN5qBjbFpEn+e6dt2+xuMFW9uo+YT57sC5cvvdQ7LL37bnYeHyhmBGwUlcaNpSef9M0Zxo/3UZ6hQ6t+3tde8z+gnTpJr74qbbll1c+ZK3be2Ue+nn3WFz8CqLzZs32Xxnr1/B2uxo2zX0Pz5t6Lf8QIackSaa+9vFvQ4sXZrwUoFgRsFB0z30hlwgQfbT7uON9hccmSTTvf6NFSr15Shw4etOP4Axq1v/3NR/zPO0+aOjXuaoD8sHChh+sff/QOH61axVtPr17S559Lf/2rNGCA//578knemQKiQMBG0WrfXnrrLW+ZNXSo94996630zvHGG75gqV07D9dNmkRSauyqVZMGDfL57H37Mo8T2JiffvLfDTNn+sjxDjvEXZGrX1+69Vbpgw98ZPuYYzx4z54dd2VAYSFgo6jVqCH9858erKtX9/6xl11WuQD55pveaaNtWx/Fbto08nJj1aKFj3qNG+cvSgCUraREOvZYD7GPPSbts0/cFf3Srrv64sdbb/UdIbt08X+XlMRdGVAYCNiApO7dfcrISSdJ118v7blnxVMh3n7bw3WrVh6umzXLXq1x+sMfvH/vDTf4Cwxk3/Ll0ooVcVeB8oQgnXGG9Pzz3sHjyCPjrqh8NWr49K/PP/cpYH//u7T77v4iGkDVELCBpM0398WPTz3lPWN//Wsfsd1wfuLYsdLBB/uI7ujRvilLMbn9dp9e068fi6SiFoI0ZYo0cKB05pk+jalhQ2//2KOHv9AZNy6alpPYNFdc4b9HrrzSv2f5oFUr6bnn/Hfft99Ke+zh87SXLYu7MiB/WSig1Q1du3YN43jpjQz4+msfzS7tDvLAAz4F5L33pAMP9N0hx4zxOYzF6IMPfJT/6KP9LfAoNswoRkuW+HP73nveSu2996RFi/y6Bg08+HTr5iPYo0ZJn3zi1225pY9AHnCAf7RpE9uXUNTuukv6y1+8pWVUG8lEbckSb+d3771Sy5b+NfXuHXdVQG4ys/EhhK5lXkfABsq2bp2P1l58sfe0vuQSH5Vq1szDdYsWcVcYr2uv9dG6Rx7xLixIz7p10hdfrA/S777rb9WH4MGsSxcP0926+RSmzp19sWmq777zF4GjRvnH11/78fbt14ftHj3yf8OjfPDUU+sXDD79dPQbyUTtvfekP/3Je3gfeaR0xx38zgM2RMAGqmDiRO+c8emn3i3kjTd8ZKfYrV3ri0InTvT5623bxl1Rblu0yBeVlYbp999f3xqyUaP1QbpbN58Hm24oDsEDe2nYHjPG52tXqybtttv6wN2tm1SzZsa/vKI2ZoxvR77bbv7c16kTd0WZsWaNL3y8+mp/wXDDDT7tpXr1uCsDcgMBG6iilSt9HmyvXozipJo1y+cF77CDh4x8H7XLlLVrfTS6NEy/+66HX8kD7/bb/zxQd+z4y9Hpqlqzxh+/NHB/8IGPmter5y+MSgN35875OZUhV3zyiXcJadnSuxEV0iZTpWbM8I1pXnnFpykNGOCbdAHFjoANIDJDhvgUkWuukS6/PO5q4rFwoYfZ0kD9wQfrF4g1brw+SHfv7qOcm2+e/RoXL5Zef3194J42zY83b74+bO+/f/Et2q2KWbP8e1qjhi9+3nbbuCuKTgjS449715GFC73jyD//mb1t34FcRMAGEKnjj5eGDZPeecdHuApZSYlPF0qdO/3ll35d9eo+spcaqNu3z80R4lmzpFdf9bD92msemiR/N6I0cO+zDwGqPAsW+Jbj33/vbTt/9au4K8qOH36QLrrIF363a+c7Qe6yS9xVAfEgYAOI1OLFPlVks82kjz+OZ4Q2Kt9///PR6Q8/9K2vJV/w2r37+kDdtatPwcg369b59610dPvtt6XVq32u9l57rQ/cv/41828l//736OHrD1591Z+jYvPmm/7O1fffe8eRU06Ju6L8s3atv1hPJKRateKuBpuCgA0gcm+95XN7Tz5ZevDBuKvZNCUlPqc2de70jBl+XY0a0s47/3x0uk2b3BydrqqffvLvZ2ngnjjRj9MO0Oe2H3aY9PLL0vDh/u9iNX++dNxx/g7IGWd41yWCYuV8952/QHn1Ve9Sdeyx3hp2jz0K83dKoSJgA8iKyy7znTCfesp3fcx169Z5eHz9df944w1p6VK/bpttfj46veuuhdMdIl3ffbd+OsmoUdI33/jx7bZbH7b326/w2wGG4CO1gwb5Qr/TT4+7oviVlPjai5tu8nD41FN0WdqY0aO9M9Xixf47c/Jk6ZlnvL99hw7SiSd6+C7GF7D5hoANICvWrPENaKZP9+Caa39oQ/A/Zq+/7n/k3nhj/dzjDh08JO67r7/lv+22jCSVpaJ2gLvv7gslDzzQfw4KbTrJJZdIN97obeuuvDLuanLL8OE+AlunjvTEE/5/CT+3dq30r3/5gvBOnXzdyg47+HVLl/qLk8GD/feS5L+LTjzRBysaNIitbFSAgA0ga6ZO9bm63bp5AMt0+7l0hOBhf/To9aPU333n17Vu7fNo99vPP3LtxUC+WL3ae3pv2A6weXMfhevXz9sS5rs77pDOO8/7QN9zDy++yvLFF9IRR/jvgJtu8k4jPE9u3jxfDD5mjIfmu++W6tcv+7azZvkGXoMHe7efOnX8eT3pJJ+iVWgvXPMZARtAVj3wgL99fvPN0j/+kd3Hnj17fZgePVqaO9ePN2/uQbo0VLMxTjQWL/Z+yY8+Kr34ok8h+PWvPWgff3x+tgF84gmfa3z44d41g4BTvmXLfBrN009LRx/t6zEKadHzpnjlFX+xuXy5vzg7+eTK3S8EXw8yeLA0dKj/32re3KeXnHRS8XSuyWUEbABZFYK/rfn88z6iufPO0T3WvHnrw/Trr69flNikyc8DdceOjKZl2/z5HgwGD5bGjfNg+vvfe9g+7LD8mNM+erR08ME+v/iVV6TateOuKPeFIP3nP9LFF/tUiGee8c/FpqTEe4XfcIPUpYtPCenSZdPOtXKl/z4dPFgaOdKnm+yyi4+GH3ecdzRC9hGwAWTdwoU+v7BRIw9XmeqnPH++v81aOkpdukNio0bSb3+7PlD/6lfxTk/Bz02e7G97P/KIv6vQoIGPcPbrJ/3mN7n5vfr4Y/+Zat3au6oU+iLOTBs92rtjrFrlC0OPOCLuirJn7lx/x+att6Q//lG6887M/Q78/nvf9GfwYOmjj7zD0cEHe9ju2ZMXgdlEwAYQi1GjfMHb2WdLd921aedYvNgX/ZSOUk+a5Mfr1/eNUEpHqXfaibfu88G6df4C6ZFHfFHX8uUeYEvna+fKSOfMmd5BpmZNb9fYokXcFeWnr76SjjrK38m6+GLp2msL///pyJEedleulO67z3+2o/Lppx60H33U381r1Ejq08cfv1s33rWLGgEbQGzOP1/q39/f3jz00I3fftky3+ikdMrHRx/5W8516nh3j9JAveuuvrEN8tePP0rPPecBYdQoD9977OFBu08f32Y+DvPn+8/awoX+s9i5czx1FIpVq3yB6P33e5eZxx/3KVyFZs0ab7t3882+o+uwYdl7wbh2rfcjHzzYO7rQ8i87CNgAYrNypYemb7/11n0bLnJbsUIaO3Z9oP7gA/9jUbOmj8CUTvnYYw82sShk8+ZJjz3mAWHiRH/xdOihHrYPPTR73/vly/1n7tNPPbB0756dxy0GDz8snXWW/w54+mnf+bRQzJnjLwrffdc33enfP741BkuX+vM7eLC/WyT5VKcTT/R3E2j5lzkEbACx+uwz/2Pao4f/4v/gg/VTPt57z1u9Va8u7bbb+kC9556Zm7OI/PLJJz6FZMgQf2G2xRYeXvr1i/Zt79Wrpd69fVOdZ5/1+azIrPHjfQH0t996q7pTT427oqobMcI7g5SU+AZEffrEXdF6s2b59JHBg6Uvv1zf8u/EE/3dhEKfrhM1AjaA2N15p3TuuT4yvXq1h6Rddlk/5WPvvWnnhZ8rKfGw+8gj63e622679W97Z7LV4rp13vrs0Ue9zWQhBL9ctWCBLwAcNcrbed55Z36+O7V6tc8r79/fW1EOG+Y/n7koBO9XP2jQ+pZ/22zj/49OPLEwetXHgYANIHYh+B+jlSs9UO+zj49MApVR+rb3I4/4ux+Sdx/p18+7kVS1w8eFF/rc2Wuv9Xm0iNbatb4b5vXX+ztXTz/tu6fmi5kzvUPKhx9K55zjPzv50r1j1SpfEzNo0Ppe9bT82zQEbABAwZgzx6ePDB7sbRpr1fK+2v36eZ/tdBe/9u/vi3HPPttHU+m8kD3PPuvBrlYt39CnR4+4K9q44cO99Z7kG+n84Q/x1lMV33+/vlf9+PE+ZeTgg/3dHFr+bRwBGwBQcELwHuuPPOKdKRYskJo29ekH/fr5qNzGwvLjj/vtjzrKgwZzUrNvyhTpyCP9xdINN0gXXJCbL3JWrfKdae+6y0fdhw6V2rWLu6rM+fRT/7/06KPSN9/4u0LHHiuddlphLUjNJAI2AKCgrV4tvfSSB4QRI/xyly4etPv2LXv6wahR3qFkzz39vozWxWf5ch8VfvJJHxF++OHcWpMxbZqHzY8+kv76V+mmm3w9SSEqq+Vfjx7SJZdIv/tdbr74iQsBGwBQNBYt8qA2eLD0zjseCHr08LB95JEe3MaPl/bd10cg33xTatgw7qoRgnTrrdJFF3kP52eekRKJuKvyxYunnebvbgwc6NORisXSpd4Z5dZbvZVm166+luaII3Jz99VsI2ADAIrS9Onr25TNmOGtH484wkev69TxHuzNm8ddJVKNGSMdc4yPnA4cGN8c5xUrfG7+ffd5e8ihQ33X0WK0apX/H/r3v300v1MnfyHUt2/hjuRXRkUBm9cfAICC1b699M9/eih4+20fxX7hBW/L9/LLhOtctO++PhXjV7/yufEXXeSdLrJpyhQP1ffd53PC33yzeMO15ItQTz/d58kPHeovTv/4R///ddttvisrfo4RbABAUVm1yj/Y0S63rVrl853vu8+n+Awd6otYozZkiO/GWLu2t7I79NDoHzPfhOAvUG+8UXrjDWnLLX2fg3POkRo3jru67GEEGwCApFq1CNf5oFYt6d57fcHjO+9Iu+7qfaej8tNPPtf6hBN845gJEwjX5TGTDjrIp/OMHSvttZd01VU+yn/++dLcuXFXGD8CNgAAyFknn+whrlo13/H1v//N/GNMniztsYf3tb7kEt/MqGXLzD9OIere3Tv3TJrk6xvuuMMXD592mjR1atzVxYeADQAActouu6zv/PKnP3l4W7kyM+ceNMi7Y3z3nbdrvP56qUaNzJy7mGy/vbfJ/PJL/x4NGeJdYI4+2r93xYaADQAAcl7jxtLIkb6V/YMPSr/5jTR79qaf78cffcfCk0+Wdt/dp4T8/vcZK7dotW3rm/HMmuUt/V55xV/AHHigvzNQQEv/KkTABgAAeaF6denaa32L9alTfV72q6+mf55Jkzz0PfKIdOWVfg46ymTWVlv5uwFz5vhiyIkTfbFq9+7+/Vu3Lu4Ko0XABgAAeeWww3zB49Zb+6jzjTdWbmQ0BOmBB3zEetEi74d+9dUe3BGNhg291eLMmdI990jff+9ztXfYwXtrr1kTd4XRIGADAIC807Gj9N57Psf3kkt8Q5qlS8u//bJl3iHk9NO968WECb71N7KjJB2iUwAAFTJJREFUTh3prLP8nYchQ/xFzUknSdttJ915p3dxKSQEbAAAkJfq15cef9y38h4xwkemP//8l7ebMMGnhAwdKl1zjfdw3nrr7NcLX0B6/PHSJ59Izz8vbbut99Bu00a67jp/Z6EQELABAEDeMpP+9jfptdc8nO2+u/Tkk35dCN5Lu1s3aflyafRo6fLLmRKSC8y8z/jbb0tvvSXttpt/b1q3li68UJo3L+4Kq4aADQAA8t5vf+tbrO+wg3TMMdLf/y716SP9+c/e3m/CBL8Ncs/ee0svvODfo549pVtu8RHtM86Qpk+Pu7pNQ8AGAAAFoUUL37r7z3/2aSNPPy3dcIO398vGNuuomp12kh57zOdpn3KKNHCgz7U/7jgP3/nEQgE1JOzatWsYN25c3GUAAICYPf+8t4rbbbe4K8GmmjdPuu02n+azbJl08MG+oHXvvX2KSdzMbHwIoWtZ1zGCDQAACk7PnoTrfLfNNtJNN3kv7euuk8aNk/bZxwP288/n9qY1BGygEIQgzR8rzRgorVkedzUAAGRMo0bSpZf67pB33inNnSv16iXtuKO3/CspibvCXyJgA/lsXYk0e5j0Sndp1F7Se6dIz7WWJl0trfoh7uoAAMiYunWl/2vv7oPrqus8jr+/uXlqkrZp0wegaW2hpaVFpFgRxdVB1x0QFnSdHXBZdVh3XVhRQF1BnfGfdRTHJ1RAFwEfBtR1WHzcEWXRWde1PNYWaAultAUCRdKHNEmfch+++8fv3Obk5iZNem9y7kk/r5k795xzc2++ObkPn/s9v3PO1VfD1q3hJDWFQji2+U03JV3ZcBqDLZJG2V7Yejs8/TU48Dy0LYUV10H7q+GpL0PXz6C+FZZeCSs+Ci06B7CIiEwthUIYKnLuudDRMfm/f7Qx2PWTXYyIVGD/c/D012HrtyHXB/PeAmu+AQsuAos2SM37C+h5EjZ9AZ6+CbZ8A06+AlZ+AtpOTrZ+ERGRKqmrg4svTrqK8tTBFkmDXQ/DU1+BF+4J84suDR3rjrJfnAf1b4NNX4Rtd4LnYNFlsOqG0OkWERGRYzZaB1sBW6RWFfLw4s9CsO7+P2iYCUs/CKd+GFoXju+xDu4Mj/PMtyDXDwsuhlWfhDnnTEztIiIiU5wCtkiaZPth23fC8I7+bdC6BFZcG4Z5NEyv7LEP74EtN4ex2wN7YP55sOpTMP9ttXFQURERkZRQwBZJgwNdIfw+8++Q7YE5b4AVH4POd0Jdprq/K9sPz34bNn8JDr4Es18XOtqdlwyO5RYREZERaSdHkVq2Z10YvvHcfwAFWPhuWH4dzH3DxP3OhrYwhnvZv8D274cdIv/3b2DmSlh5A7zqMqhrmLjfLyIiMoWpVSWSBC9A1y/gv8+D+14bDqt36tXw11vhTT+e2HAdl2mCpf8EFz0Fb/wBWAbWvg9+cSpsuRVyByenDhERkSlEQ0REJlPuQOgYP/VV6NsCLQth+TVwyj9C48ykqwtnhHzpv2Dj52DXWmieH46jvexKaJiRdHUiIiI1Q0NERJJ28OVofPU3w86Fs9fAG38Ii95dW0MxzMIxtU+6EF75fQja66+HjZ8PHfbl10DznKSrrK5CHno3w+6Hw2XfJqAA1EU7flo0Lr04bUNvi99e+vPjuf9YHq843TgrHNO8eJl2osbOi4jUEAVskYnU80QYX73jB1DIhp0IV3wU5r6pto/aYQbz3xIuux+FTZ+HjZ8Nf8vSD8JpH4OWzqSrHD/3sDNpMUzvfhj2PBoOXQjhUIjtr4a6JsDDUB48nJI+Pu8+dP6otzlQiN1WMj+ex/YC5HqjZZG6JmhbEgXuU4aG77Yl4ayeIpVyh76tYevWrrVw4AVoPx1mvxZmnRWeb7X8viYyiTREpBq6/wieh/q2cBi1+ulhJ7JMi95sjqaQh/yBEHCsHprmpH+ducPOX4cw+vL94Xlw8hWh+ztjWdLVHbt9m8POkDvuCt3SJe+D066v7b9poAd2PzI0UB96OdxW1wizzoSOswcv05eloxOcH4ADz4fDOB65PBuu+54NZ/mMa55fJnir+y1Hke2HPY+EMN29FnY/CId3hdvqp0ProjDUrZANyxraYfZZIXAXL20n6/klU5YO0zfRfrkybGIuZXUhdMeD95AQXjrfVn75kenW5N6o3CF/MAThXD/k9oc331z/0GW5/pLl+wens/2QL7lfvmQnukwztCwKb9xlrxeGn6lF+UOw4+4QrPdtCsHl1A/D0n+GptlJV1c9/TvC4f223QGFAVj4t+HskLPOTLau/GHYuyEK0g+F674tg7fPWA6zoyA95/XQfkbYyXOqcQ/DkMqF7/5toesY735nmsOx1suFb3W/jx/u4XlS7E7vWgs9jw8+V2YsD4cOLV5mrAyHD80fhn1Pwp7HBi89T4T3BghbhWatHhq6py9V6JYpQQF7ou1dD4d3Q7YvdI5y/WE6G03n+srPF38uf2Dsv6s0sJeG8pGCe6YlBMB4IC4XeMsG5WiecTxXMi1RbcVLa2y6LbqtZFn+UPjwP/A87H8+XB/cOfyxm+eNHsKb501uF/xQNzxzK2y5BQ53Q/trwhCKRZdCpnHy6phsB/8cToaz5ZbwnD7pHeGkNXPPnfjf7QXo3TK0M92zfrCT1nxCCNHFzvTsNdDYPvF1pcGw7ncsfJftfp8wQvg+BaadoKCUVrn9YevOkUD9YHj/gvB+3PH6WKA+Z3xNgvwA7NtYErofh8Lh6PGnw+zVMCsWumecqueSpI4Cdq0r5KOg23fsIT1+n+J40rGoa4oCeGtJIC4JwA3jCMr1LdV7o8wfhoMvhsBdDN3x6/3PDf+CUtcUjs7ROlIIXxhqrNS+zeFoINu/Hz44TrowjK+ef176h7mMx0BPCNlP3xQ2H897M6z8FJz4V9VbDwd3wq6HYuOmH4Fsb7itvi0E6PhQj5bO4+t/UC3Dut/PDu2Ej7n7vQQaO8KRZ+pb9b9Imnv4/w3rTufD7dNPHdqdnrmq+ie3KmSj0L0uFro3hMYKhNfxrDNLOt3Lq1+HSBUpYB9vvBDrQhfD94EQKoeE5NbaOoLFsXCHgb2xwF0mhB98iWHd96Y5w4N3fLp5fvkvCe7w59/C5i/Dzl+FgLHkfbD8Wph52qT8yTUrtx+evQM2fzHsSDhrdehod75rfB+S2d7w4RvvTh/oCrdZfRjaEQ/TM1boQ3iyFLvffc/C/m1Dw3e57jdEQ+VmhLDdODMK3bHphhlhGMGQ6zLTmWYF9bEaV3f69dDUkUydhVwYTrc3Frr3rh8cOphpGR66Z6yAOh2fYVK4hwZWIRe2iGsLwzAK2HJ8yw+EkD2s+12cfm5417+uIXS64yG8cSZsvyt0XZrnwbIPwbKroHluMn9XrcoPhB0hN90Ifc+E7tjKG2Dx5cOHzBSyYbzm7lh3et9mjnwhajtlaJietRrqp036nyRjMKT7vR2yPTCwL3xhyvZCdl/JdWy6dF+Mcqw+vAbjYb00uI8W0I8E9Sk2bKsWutPVVMhB71ODne69j8GePw1uqcxMC6F7VmxnypkrFbqPxj188RrYHbY0Hi5ejzI9sHtwCwMWXj+N7eEwoY3tYafW4vyR6TLzDe1TdkuWArbIaNzDB3257veRLviLYcvAzFVhGMjiv6vdnS1rRSEPXfeGY2nvXR++sJz28bD14MhQj3WD4zKb5kRBujh2+nXJddZkcuUHomFvsdBdDOe52HS5cB6/Lo7BH01dUyx4R5f66dH09LEvq5+eTFDN7Q+HziyG6d0PwqFXwm31bdFOvPGx01PgNVTIQ9/TQ4eX7P3TYGMk0xz2fYkfwWTmqvRvoR1JMSyPFIpHCs3F99phLIyxb5oTLo0dg9NNHeEMv9l9YTjgQE/YapyNprPRfG7/6DVb/fBQfrT5eEiv0c9bBWyRShVyYRNr8wlT8lv4hHKHnfeFoN39h7AsMy18CMa7062LtW6lMvlDg+E81zs0qA8L5/sGh9Ble6N9XHrD/JGu3VFkWmJBfXpJCB9lWX08uEc7pY80JG3/9nCIvCPd6Q2x7vSyku706bXdna6m4o7O8eEle9YNDlOqawrDyVoWhHBX1zB4XVcP1lAyHbuuayiZLr1/mWXlbhv22KXL6qKw3H/0TnLpsuJRWoaxEIqbOkYOzKXTDe2VP28K2ei1ViaEl5svBvPi9NFec5nmwcBdLpQvfFdoykwyBWwRqQ171oVuyMxV2qQrtetIRz0WuuMhfCzLigF/LF11GDwCVDGQ17eEw78e6U63Du1Od5wz9c6qWikvhBPh7FkXDS15LAqjufB/8BGui9OTrXiG1uIXpnK3N84eHoxHC8zVCMtJyB8qCd9HCeWl82ffBqdcMellK2CLiIgkIX94hEAeC+HlgnyuD1pPhrnx7rS+lE4Y9xB0RwrfhWwI6p4tE9jLLRvlceKPRyGE4nKBubFdOxaORfEMtwl8sRgtYE/4q9XMzge+BmSA2939xpLbLweuj2b7gavcfcNY7isiIlLTMk2QmQtoZ+iaZhaGdlBfs+N9ZQRmYctojZnQr0ZmlgFuAS4AVgLvMbOVJT+2HXiLu58B/Btw2zjuKyIiIiJSUyZ628PZwFZ33+buA8CPgEviP+Duf3T3vdHsg0DnWO8rIiIiIlJrJjpgLwBeiM13RctG8gHgV+O5r5l90MweNbNHu7u7KyxXRERERKQyEx2wyx1zq+xelWZ2HiFgF8djj+m+7n6bu69x9zVz52qMm4iIiIgka6J3cuwCFsbmO4GXSn/IzM4AbgcucPfd47mviIiIiEgtmegO9iPAMjNbYmaNwGXAz+M/YGaLgHuB97r7lvHcV0RERESk1kxoB9vdc2Z2NfBrwqH27nT3jWZ2ZXT7t4DPAB3ArRbO4paLhnyUve9E1isiIiIiUimdaEZEREREZJxGO9GMThEkIiIiIlJFCtgiIiIiIlWkgC0iIiIiUkUK2CIiIiIiVaSALSIiIiJSRQrYIiIiIiJVpIAtIiIiIlJFCtgiIiIiIlWkgC0iIiIiUkUK2CIiIiIiVTSlTpVuZt3Acwn9+jnAroR+91ShdVg5rcPKaR1Wh9Zj5bQOK6d1WDmtw5G9yt3nlrthSgXsJJnZoyOdj17GRuuwclqHldM6rA6tx8ppHVZO67ByWofHRkNERERERESqSAFbRERERKSKFLCr57akC5gCtA4rp3VYOa3D6tB6rJzWYeW0DiundXgMNAZbRERERKSK1MEWEREREakiBewKmdn5Zva0mW01sxuSrieNzGyhmf3OzDab2UYzuybpmtLIzDJm9icz+2XStaSVmbWb2T1m9lT0fHxD0jWljZldF72OnzSzH5pZc9I11Tozu9PMXjGzJ2PLZpvZ/Wb2THQ9K8ka02CE9fjF6PX8uJn9xMzak6yx1pVbh7HbPm5mbmZzkqgtbRSwK2BmGeAW4AJgJfAeM1uZbFWplAM+5u6nAecAH9J6PCbXAJuTLiLlvgbc5+4rgNeg9TkuZrYA+Aiwxt1PBzLAZclWlQrfBc4vWXYD8IC7LwMeiOZldN9l+Hq8Hzjd3c8AtgCfnOyiUua7DF+HmNlC4O3A85NdUFopYFfmbGCru29z9wHgR8AlCdeUOu6+093XRdN9hFCzINmq0sXMOoELgduTriWtzGwG8GbgDgB3H3D3nmSrSqV6YJqZ1QMtwEsJ11Pz3P33wJ6SxZcA34umvwe8c1KLSqFy69Hdf+PuuWj2QaBz0gtLkRGeiwBfBT4BaMe9MVLArswC4IXYfBcKhhUxs8XAauChZCtJnZsIb36FpAtJsZOBbuA70VCb282sNemi0sTdXwS+ROhy7QT2uftvkq0qtea7+04ITQhgXsL1TAX/APwq6SLSxswuBl509w1J15ImCtiVsTLL9O3uGJlZG/CfwLXu3pt0PWlhZhcBr7j7Y0nXknL1wFnAN919NbAfbZYfl2ic8CXAEuAkoNXM/j7ZqkTAzD5NGI54d9K1pImZtQCfBj6TdC1po4BdmS5gYWy+E20OPSZm1kAI13e7+71J15My5wIXm9kOwjClt5rZXcmWlEpdQJe7F7ee3EMI3DJ2fwlsd/dud88C9wJvTLimtPqzmZ0IEF2/knA9qWVm7wcuAi53HZt4vE4hfGHeEH3GdALrzOyERKtKAQXsyjwCLDOzJWbWSNiZ5+cJ15Q6ZmaEca+b3f0rSdeTNu7+SXfvdPfFhOfgb91dXcNxcveXgRfMbHm06G3ApgRLSqPngXPMrCV6Xb8N7Sh6rH4OvD+afj/wswRrSS0zOx+4HrjY3Q8kXU/auPsT7j7P3RdHnzFdwFnR+6WMQgG7AtGOE1cDvyZ8iPzY3TcmW1UqnQu8l9B5XR9d3pF0UXJc+jBwt5k9DpwJfC7helIl6v7fA6wDniB8xugscEdhZj8E1gLLzazLzD4A3Ai83cyeIRy94cYka0yDEdbjzcB04P7os+VbiRZZ40ZYh3IMdCZHEREREZEqUgdbRERERKSKFLBFRERERKpIAVtEREREpIoUsEVEREREqkgBW0RERESkihSwRURSzMzyscNbrjezqp190swWm9mT1Xo8EZHjRX3SBYiISEUOuvuZSRchIiKD1MEWEZmCzGyHmX3BzB6OLkuj5a8yswfM7PHoelG0fL6Z/cTMNkSX4inOM2b2bTPbaGa/MbNp0c9/xMw2RY/zo4T+TBGRmqSALSKSbtNKhohcGrut193PJpzN7qZo2c3A9939DOBu4OvR8q8D/+PurwHOAopnpV0G3OLuq4Ae4N3R8huA1dHjXDlRf5yISBrpTI4iIilmZv3u3lZm+Q7gre6+zcwagJfdvcPMdgEnuns2Wr7T3eeYWTfQ6e6HY4+xGLjf3ZdF89cDDe7+WTO7D+gHfgr81N37J/hPFRFJDXWwRUSmLh9heqSfKedwbDrP4L47FwK3AK8FHjMz7dMjIhJRwBYRmboujV2vjab/CFwWTV8O/CGafgC4CsDMMmY2Y6QHNbM6YKG7/w74BNAODOuii4gcr9RxEBFJt2lmtj42f5+7Fw/V12RmDxGaKe+Jln0EuNPM/hXoBq6Ill8D3GZmHyB0qq8Cdo7wOzPAXWY2EzDgq+7eU7W/SEQk5TQGW0RkCorGYK9x911J1yIicrzREBERERERkSpSB1tEREREpIrUwRYRERERqSIFbBERERGRKlLAFhERERGpIgVsEREREZEqUsAWEREREakiBWwRERERkSr6f92oZ7wPe09DAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "plt.plot(train_loss, label = 'training_loss', color = 'b')\n",
    "plt.plot(val_loss, label = 'val_loss', color = 'orange')\n",
    "\n",
    "plt.title('Training and Validation Loss by Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('weighted_log_loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predictions(test_df, model):    \n",
    "#     test_preds = model.predict_generator(TestDataGenerator(test_df,TEST_BATCH_SIZE, SHAPE, PATH_TEST_DATA, verbose = 1))\n",
    "#     return test_preds[:test_df.iloc[range(test_df.shape[0])].shape[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator_test = TestDataGenerator(dataset = test_df, batch_size = TEST_BATCH_SIZE,img_size = SHAPE,\n",
    "                                                        img_dir = PATH_TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_STEPS = int(len(data_generator_test) / TRAIN_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_STEPS = int(test_df.shape[0] / TRAIN_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15154"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_generator_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15154/15154 [==============================] - 1119s 74ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = vgg19_model.predict_generator(generator = data_generator_test, \n",
    "                                      #steps = TEST_STEPS,\n",
    "                                      verbose = 1,\n",
    "                                      use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121232, 6)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121232, 6)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = preds[:test_df.iloc[range(test_df.shape[0])].shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(meta_data_df, predictions):\n",
    "    df = pd.DataFrame(predictions, columns=meta_data_df.columns, index=meta_data_df.index)\n",
    "    df = df.stack().reset_index()\n",
    "    df.loc[:, \"ID\"] = df.id.str.cat(df.subtype, sep=\"_\")\n",
    "    df = df.drop([\"id\", \"subtype\"], axis=1)\n",
    "    df = df.rename({0: \"Label\"}, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df = make_df(test_df, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df = test_pred_df[['ID','Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df.to_csv('../data/output/submissions/submission_model_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(727392, 2)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2353/2353 [==============================] - 1439s 611ms/step\n"
     ]
    }
   ],
   "source": [
    "val_preds= vgg19_model.predict_generator(generator = data_generator_val, verbose = 1, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = val_preds[:train_df.iloc[val_idx].shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_pred_df = make_df(train_df.iloc[val_idx], val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_df = val_pred_df[['ID','Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(903366, 2)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_df.to_csv('../data/output/submissions/val_pred_model_4.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
