{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Intracranial Hemorrhage Detection\n",
    "\n",
    "## Model 2 \n",
    "\n",
    "#### Kristina Joos\n",
    "\n",
    "---   \n",
    "\n",
    "|                 \t|                                                        \t|\n",
    "|:----------------:\t|:-------------------------------------------------------:\t|\n",
    "| Model           \t| VGG 16 (242x242), trainable = False                       |\n",
    "| Preprocessing   \t| Augementation Flip, Single Windowing                   \t|\n",
    "| Class Balancing \t| Oversampling                                           \t|\n",
    "| Loss Function   \t| Binary_crossentropy                                      \t|\n",
    "| Regularization  \t| Early Stopping, Drop Out Layers 0.3 \t                    |\n",
    "| Epochs Run      \t| 50                                                     \t|\n",
    "| Time Run (h)   \t| 1                                                       \t|\n",
    "|                 \t|                                                        \t|\n",
    "| Test Sores      \t| Accuracy: 0.8731 Loss: 0.3220                             |\n",
    "| Validation      \t| Accuracy: 0.8804 Loss: 0.3136                             |\n",
    "| Leader Board    \t| Score: 0.52307 Rank: 410/1345 (31%)                     \t|\n",
    "\n",
    "\n",
    "oss: 0.3220 - accuracy: 0.8731 - val_loss: 0.3136 - val_accuracy: 0.8804"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import collections\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "from math import ceil, floor, log\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "#import tensorflow.keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import sys\n",
    "\n",
    "# from keras_applications.resnet import ResNet50\n",
    "from keras_applications.inception_v3 import InceptionV3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    " \n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, ShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_resnet_50\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as preprocess_vgg_16\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50, VGG16, VGG19\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_resnet_50\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as preprocess_vgg_16\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Activation, concatenate, Dropout, MaxPooling2D, Conv2D, Flatten\n",
    "from tensorflow.keras.initializers import glorot_normal, he_normal\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model, load_model, Sequential, load_model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_data = '../data/input/rsna-intracranial-hemorrhage-detection/stage_2_train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test_data = '../data/input/rsna-intracranial-hemorrhage-detection/stage_2_test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_files(path, data_name):\n",
    "    no =  len(os.listdir(path))\n",
    "    print (f'The {data_name} contains {no} files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size_directory(path, data_name):\n",
    "    size = round(sum([os.path.getsize(f'{path}'+ f'{file}') for file in os.listdir(path)])*(10**-9), 2)\n",
    "    print (f'The size of the {data_name} is {size} GB.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***TRAIN DATA***\n",
      "The size of the Training Data is 395.19 GB.\n",
      "The Training Data contains 752803 files.\n",
      "*******\n",
      "***TEST DATA***\n",
      "The size of the Testing Data is 63.64 GB.\n",
      "The Testing Data contains 121232 files.\n",
      "*******\n",
      "We have 6.2 times more train than test data.\n"
     ]
    }
   ],
   "source": [
    "print('***TRAIN DATA***')\n",
    "get_size_directory(path_train_data, 'Training Data')\n",
    "get_number_of_files(path_train_data, 'Training Data')\n",
    "\n",
    "print('*******')\n",
    "\n",
    "print('***TEST DATA***')\n",
    "get_size_directory(path_test_data, 'Testing Data')\n",
    "get_number_of_files(path_test_data, 'Testing Data')\n",
    "\n",
    "print('*******')\n",
    "\n",
    "print(f'We have {round(len(os.listdir(path_train_data))/len(os.listdir(path_test_data)),1)} times more train than test data.' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_meta_df = pd.read_csv('../data/input/rsna-intracranial-hemorrhage-detection/stage_2_train.csv')\n",
    "# Test submission as test \n",
    "test_meta_df = pd.read_csv('../data/input/rsna-intracranial-hemorrhage-detection/stage_2_sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta_df_shape = train_meta_df.shape\n",
    "test_meta_df_shape = test_meta_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4516842, 2)\n",
      "(727392, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_meta_df_shape)\n",
    "print(test_meta_df_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Seed\n",
    "SEED = 11\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "# Constants\n",
    "TEST_SIZE = 0.2\n",
    "HEIGHT = 224 #VGG 16 has 256x256\n",
    "WIDTH = 224\n",
    "CHANNELS = 3\n",
    "TRAIN_BATCH_SIZE = 2\n",
    "VALID_BATCH_SIZE = 2\n",
    "TEST_BATCH_SIZE = 4\n",
    "SHAPE = (HEIGHT, WIDTH, CHANNELS)\n",
    "\n",
    "# Folders\n",
    "#DATA_DIR = '/kaggle/input/rsna-intracranial-hemorrhage-detection/'\n",
    "PATH_TEST_DATA = path_test_data\n",
    "PATH_TRAIN_DATA = path_train_data\n",
    "PATH_PT_MODELS = '../models/predtrained models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_pixelarray(dataset):\n",
    "    image = dataset.pixel_array\n",
    "    rescaled_image = image * dataset.RescaleSlope + dataset.RescaleIntercept\n",
    "    rescaled_image[rescaled_image < -1024] = -1024\n",
    "    return rescaled_image\n",
    "\n",
    "def set_manual_window(hu_image, min_value, max_value):\n",
    "    hu_image[hu_image < min_value] = min_value\n",
    "    hu_image[hu_image > max_value] = min_value #max_value\n",
    "    return hu_image\n",
    "\n",
    "class Preprocessor:    \n",
    "    \n",
    "    def __init__(self, path,hu_min_value, hu_max_value, augment=False):\n",
    "        self.path = path\n",
    "        self.nn_input_shape = (224,224) #was 256, 256\n",
    "        self.hu_min_value = hu_min_value\n",
    "        self.hu_max_value = hu_max_value\n",
    "        self.augment = augment\n",
    "        \n",
    "  #load the dicom dataset\n",
    "    def load_dicom_dataset(self, filename):\n",
    "        dataset = pydicom.dcmread(self.path + filename)\n",
    "        return dataset\n",
    "    \n",
    "    #Rescale the pixelarray to HU units and set to window\n",
    "    \n",
    "    def get_hounsfield_window(self, dataset, min_value, max_value):\n",
    "        \n",
    "        hu_image = rescale_pixelarray(dataset)\n",
    "        windowed_image = set_manual_window(hu_image, min_value, max_value)\n",
    " \n",
    "        return windowed_image\n",
    "        \n",
    "#     def get_hounsfield_window(self, dataset, min_value, max_value):\n",
    "#         try:\n",
    "#             hu_image = rescale_pixelarray(dataset)\n",
    "#             windowed_image = set_manual_window(hu_image, min_value, max_value)\n",
    "#         except ValueError:\n",
    "#             # set to level \n",
    "#             windowed_image = min_value * np.ones((self.nn_input_shape[0], self.nn_input_shape[1]))\n",
    "#         return windowed_image\n",
    "        \n",
    "\n",
    "    #Resize the image to the input shape of our CNN\n",
    "    def resize(self, image):\n",
    "        image = resize(image, self.nn_input_shape)\n",
    "        return image\n",
    "\n",
    "    #augment our image\n",
    "    def augment_img(self, image): \n",
    "        augment_img = iaa.Sequential([\n",
    "            #iaa.Crop(keep_size=True, percent=(0.01, 0.05), sample_independently=False),\n",
    "            #iaa.Affine(rotate=(-10, 10)),\n",
    "            iaa.Fliplr(0.5)])\n",
    "        image_aug = augment_img.augment_image(image)\n",
    "        return image_aug\n",
    "    \n",
    "    def fill_channels(self, image):\n",
    "        filled_image = np.stack((image,)*3, axis=-1)\n",
    "        return filled_image\n",
    "    \n",
    "    def preprocess(self, identifier):\n",
    "        filename = identifier +  \".dcm\"\n",
    "        dataset = self.load_dicom_dataset(filename)\n",
    "        windowed_image = self.get_hounsfield_window(dataset, self.hu_min_value, self.hu_max_value)\n",
    "        image = self.resize(windowed_image)\n",
    "        if self.augment:\n",
    "            image = self.augment_img(image)\n",
    "        image = self.fill_channels(image)\n",
    "        return image\n",
    "    \n",
    "    def normalize(self, image):\n",
    "        return (image - self.hu_min_value)/(self.hu_max_value-self.hu_min_value) * 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Generator(Sequence):\n",
    "    \n",
    "    def __init__(self, dataframe,\n",
    "                 preprocessor,\n",
    "                 batch_size,\n",
    "                 shuffle,\n",
    "                 num_classes=6,\n",
    "                 steps=None):\n",
    "        \n",
    "        self.preprocessor = preprocessor\n",
    "        self.data_ids = dataframe.index.values\n",
    "        self.dataframe = dataframe\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.input_shape = (224,224)\n",
    "        self.preprocess_net = preprocess_vgg_16\n",
    "        self.num_classes = num_classes\n",
    "        self.current_epoch=0\n",
    "        \n",
    "        self.steps=steps\n",
    "        if self.steps is not None:\n",
    "            self.steps = np.round(self.steps/3) * 3\n",
    "            self.undersample()\n",
    "\n",
    "    def undersample(self):\n",
    "        part = np.int(self.steps/3 * self.batch_size)\n",
    "        zero_ids = np.random.choice(self.dataframe.loc[self.dataframe[\"any\"] == 0].index.values, size=2*part, replace=False)\n",
    "        hot_ids = np.random.choice(self.dataframe.loc[self.dataframe[\"any\"] == 1].index.values, size=1*part, replace=False)\n",
    "        self.data_ids = list(set(zero_ids).union(hot_ids))\n",
    "        np.random.shuffle(self.data_ids)\n",
    "\n",
    "    # defines the number of steps per epoch\n",
    "    def __len__(self):\n",
    "        if self.steps is None:\n",
    "            return np.int(np.ceil(len(self.data_ids) / np.float(self.batch_size)))\n",
    "        else:\n",
    "            return 3*np.int(self.steps/3) \n",
    "    \n",
    "    # at the end of an epoch: \n",
    "    def on_epoch_end(self):\n",
    "        # if steps is None and shuffle is true:\n",
    "        if self.steps is None:\n",
    "            self.data_ids = self.dataframe.index.values\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(self.data_ids)\n",
    "        else:\n",
    "            self.undersample()\n",
    "        self.current_epoch += 1\n",
    "    \n",
    "    # should return a batch of images\n",
    "    def __getitem__(self, item):\n",
    "        # select the ids of the current batch\n",
    "        current_ids = self.data_ids[item*self.batch_size:(item+1)*self.batch_size]\n",
    "        X, y = self.__generate_batch(current_ids)\n",
    "        return X, y\n",
    "    \n",
    "    \n",
    "    \n",
    "    # collect the preprocessed images and targets of one batch\n",
    "    def __generate_batch(self, current_ids):\n",
    "        X = np.empty((self.batch_size, *self.input_shape, 3))\n",
    "        y = np.empty((self.batch_size, self.num_classes))\n",
    "        for idx, ident in enumerate(current_ids):\n",
    "            # Store sample\n",
    "            image = self.preprocessor.preprocess(ident)\n",
    "            X[idx] = self.preprocessor.normalize(image)\n",
    "            # Store class\n",
    "            y[idx] = self.__get_target(ident)\n",
    "        return X, y\n",
    "    \n",
    "    # extract the targets of one image id:\n",
    "    def __get_target(self, ident):\n",
    "        targets = self.dataframe.loc[ident].values\n",
    "        return targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Meta Data Frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_usable_df(df):\n",
    "    label = df.Label.values\n",
    "    new_df = df.ID.str.rsplit(\"_\", n=1, expand=True)\n",
    "    new_df.loc[:, \"label\"] = label\n",
    "    new_df = new_df.rename({0: \"id\", 1: \"subtype\"}, axis=1)\n",
    "    piv_df = pd.pivot_table(new_df, index=\"id\", columns=\"subtype\", values=\"label\")\n",
    "    \n",
    "    return piv_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for Dupicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_meta_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta_df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_meta_df_shape[0] - train_meta_df.shape[0] == 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make usable Data Frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>subtype</th>\n",
       "      <th>any</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID_000012eaf</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_000039fa0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_00005679d</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_00008ce3c</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_0000950d7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "subtype       any  epidural  intraparenchymal  intraventricular  subarachnoid  \\\n",
       "id                                                                              \n",
       "ID_000012eaf    0         0                 0                 0             0   \n",
       "ID_000039fa0    0         0                 0                 0             0   \n",
       "ID_00005679d    0         0                 0                 0             0   \n",
       "ID_00008ce3c    0         0                 0                 0             0   \n",
       "ID_0000950d7    0         0                 0                 0             0   \n",
       "\n",
       "subtype       subdural  \n",
       "id                      \n",
       "ID_000012eaf         0  \n",
       "ID_000039fa0         0  \n",
       "ID_00005679d         0  \n",
       "ID_00008ce3c         0  \n",
       "ID_0000950d7         0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = make_usable_df(train_meta_df)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Check for Duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_meta_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make usable Data Frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>subtype</th>\n",
       "      <th>any</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID_000000e27</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_000009146</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_00007b8cb</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_000134952</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_000176f2a</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "subtype       any  epidural  intraparenchymal  intraventricular  subarachnoid  \\\n",
       "id                                                                              \n",
       "ID_000000e27  0.5       0.5               0.5               0.5           0.5   \n",
       "ID_000009146  0.5       0.5               0.5               0.5           0.5   \n",
       "ID_00007b8cb  0.5       0.5               0.5               0.5           0.5   \n",
       "ID_000134952  0.5       0.5               0.5               0.5           0.5   \n",
       "ID_000176f2a  0.5       0.5               0.5               0.5           0.5   \n",
       "\n",
       "subtype       subdural  \n",
       "id                      \n",
       "ID_000000e27       0.5  \n",
       "ID_000009146       0.5  \n",
       "ID_00007b8cb       0.5  \n",
       "ID_000134952       0.5  \n",
       "ID_000176f2a       0.5  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = make_usable_df(test_meta_df)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/ Val Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Label Stratified Shuffel Splitter \n",
    "Cross Validaor with stratification on multiple labels:\n",
    "https://github.com/trent-b/iterative-stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "msss = MultilabelStratifiedShuffleSplit(n_splits = 10, test_size = TEST_SIZE, random_state = SEED)\n",
    "X = train_df.index\n",
    "Y = train_df[['any', 'epidural', 'intraparenchymal', 'intraventricular',\n",
    "       'subarachnoid', 'subdural']].values\n",
    "\n",
    "# Get train and test index\n",
    "msss_splits = next(msss.split(X, Y))\n",
    "train_idx = msss_splits[0]\n",
    "val_idx = msss_splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(602242,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150561,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_df.iloc[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(602242, 6)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = train_df.iloc[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150561, 6)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loan Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Will be used as the metric in model.compile()\n",
    "    ---------------------------------------------\n",
    "    \n",
    "    Similar to the custom loss function 'weighted_log_loss()' above\n",
    "    but with normalized weights, which should be very similar \n",
    "    to the official competition metric:\n",
    "        https://www.kaggle.com/kambarakun/lb-probe-weights-n-of-positives-scoring\n",
    "    and hence:\n",
    "        sklearn.metrics.log_loss with sample weights\n",
    "    \"\"\"\n",
    "    \n",
    "    class_weights = K.variable([2., 1., 1., 1., 1., 1.])\n",
    "    \n",
    "    eps = K.epsilon()\n",
    "    \n",
    "    y_pred = K.clip(y_pred, eps, 1.0-eps)\n",
    "\n",
    "    loss = -(        y_true  * K.log(      y_pred)\n",
    "            + (1.0 - y_true) * K.log(1.0 - y_pred))\n",
    "    \n",
    "    loss_samples = _normalized_weighted_average(loss, class_weights)\n",
    "    \n",
    "    return K.mean(loss_samples)\n",
    "\n",
    "\n",
    "def _normalized_weighted_average(arr, weights=None):\n",
    "    \"\"\"\n",
    "    A simple Keras implementation that mimics that of \n",
    "    numpy.average(), specifically for this competition\n",
    "    \"\"\"\n",
    "    \n",
    "    if weights is not None:\n",
    "        scl = K.sum(weights)\n",
    "        weights = K.expand_dims(weights, axis=1)\n",
    "        return K.sum(K.dot(arr, weights), axis=1) / scl\n",
    "    return K.mean(arr, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_multilabel_loss(y_true, y_pred, class_weights=None):\n",
    "    y_pred = np.where(y_pred > 1-(1e-07), 1-1e-07, y_pred)\n",
    "    y_pred = np.where(y_pred < 1e-07, 1e-07, y_pred)\n",
    "    single_class_cross_entropies = - np.mean(y_true * np.log(y_pred) + (1-y_true) * np.log(1-y_pred), axis=0)\n",
    "    \n",
    "    print(single_class_cross_entropies)\n",
    "    if class_weights is None:\n",
    "        loss = np.mean(single_class_cross_entropies)\n",
    "    else:\n",
    "        loss = np.sum(class_weights*single_class_cross_entropies)\n",
    "    return loss\n",
    "\n",
    "def get_raw_xentropies(y_true, y_pred):\n",
    "    y_pred = tf.compat.v1.clip_by_value(y_pred, 1e-7, 1-1e-7)\n",
    "    xentropies = y_true * K.log(y_pred) + (1-y_true) * K.log(1-y_pred)\n",
    "    return -xentropies\n",
    "\n",
    "# multilabel focal loss equals multilabel loss in case of alpha=0.5 and gamma=0 \n",
    "def multilabel_focal_loss(class_weights=None, alpha=0.5, gamma=2):\n",
    "    def mutlilabel_focal_loss_inner(y_true, y_pred):\n",
    "        y_true = K.cast(y_true, np.float32)\n",
    "        y_pred = K.cast(y_pred, np.float32)\n",
    "        \n",
    "        xentropies = get_raw_xentropies(y_true, y_pred)\n",
    "\n",
    "        # compute pred_t:\n",
    "        y_t = np.where(K.equal(y_true,1), y_pred, 1.-y_pred)\n",
    "        alpha_t = np.where(K.equal(y_true, 1), alpha * K.ones_like(y_true), (1-alpha) * K.ones_like(y_true))\n",
    "\n",
    "        # compute focal loss contributions\n",
    "        focal_loss_contributions =  K.multiply(K.multiply(K.pow(1-y_t, gamma), xentropies), alpha_t) \n",
    "\n",
    "        # our focal loss contributions have shape (n_samples, s_classes), we need to reduce with mean over samples:\n",
    "        focal_loss_per_class = K.reduce_mean(focal_loss_contributions, axis=0)\n",
    "\n",
    "        # compute the overall loss if class weights are None (equally weighted):\n",
    "        if class_weights is None:\n",
    "            focal_loss_result = K.reduce_mean(focal_loss_per_class)\n",
    "        else:\n",
    "            # weight the single class losses and compute the overall loss\n",
    "            weights = K.constant(class_weights, dtype=K.float32)\n",
    "            focal_loss_result = K.reduce_sum(K.multiply(weights, focal_loss_per_class))\n",
    "            \n",
    "        return focal_loss_result\n",
    "    return mutlilabel_focal_loss_inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_16():\n",
    "    weights_path = '../models/predtrained models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "    net = VGG16(include_top=False, weights=weights_path)\n",
    "    for layer in net.layers:\n",
    "        layer.trainable = False\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vgg_16 = vgg_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MakeModel:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 pt_model,\n",
    "                 loss,\n",
    "                 metrics_list,\n",
    "                 data_generator_train,\n",
    "                 data_generator_val,\n",
    "                 epochs,\n",
    "                 num_classes=6,\n",
    "                 checkpoint_path='../models/mymodels/'):\n",
    "        \n",
    "        self.pt_model = pt_model\n",
    "        self.loss = loss\n",
    "        self.metrics_list = metrics_list\n",
    "        self.data_generator_train = data_generator_train\n",
    "        self.data_generator_val = data_generator_val\n",
    "        self.epochs = epochs\n",
    "        self.num_classes = num_classes\n",
    "        self.checkpoint_path = checkpoint_path \n",
    "        self.checkpoint = ModelCheckpoint(filepath=self.checkpoint_path,\n",
    "                                          mode=\"min\",\n",
    "                                          verbose=1,\n",
    "                                          save_best_only=True,\n",
    "                                          save_weights_only=True)\n",
    "#                                           period=1)\n",
    "#         self.reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "#                                            factor=0.5,\n",
    "#                                            patience=2,\n",
    "#                                            min_lr=1e-8,\n",
    "#                                            mode=\"min\")\n",
    "        self.earlystopping = EarlyStopping(monitor=\"val_loss\",\n",
    "                                        patience=5,\n",
    "                                        mode=\"min\",\n",
    "                                        restore_best_weights=True)\n",
    "        \n",
    "    def build_model(self):\n",
    "        base_model = self.pt_model()\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(100, activation=\"relu\")(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        predictions = Dense(self.num_classes,\n",
    "                     kernel_initializer=he_normal(seed=11),\n",
    "                     kernel_regularizer=l2(0.05),\n",
    "                     bias_regularizer=l2(0.05), activation=\"sigmoid\")(x)\n",
    "        self.model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    def compile_model(self):\n",
    "        self.model.compile(optimizer = 'adam',\n",
    "                           loss = self.loss, \n",
    "                           metrics = self.metrics_list)\n",
    "    \n",
    "    def fit_model(self):\n",
    "        return self.model.fit_generator(generator = self.data_generator_train,\n",
    "                    validation_data=self.data_generator_val,\n",
    "                    epochs=self.epochs,\n",
    "                    callbacks=[self.checkpoint,self.earlystopping],\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=-1)\n",
    "    \n",
    "    def load_weights(self, path):\n",
    "        self.model.load_weights(path)\n",
    "    \n",
    "    def predict(self, data_generator_test):\n",
    "        predictions = self.model.predict_generator(data_generator_test, use_multiprocessing = True, workers=-1)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocessor = Preprocessor(path=PATH_TRAIN_DATA,\n",
    "                                  hu_min_value=0,\n",
    "                                  hu_max_value=100,\n",
    "                                  augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preprocessor = Preprocessor(path=PATH_TRAIN_DATA,\n",
    "                                  hu_min_value=0,\n",
    "                                  hu_max_value=100,\n",
    "                                  augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preprocessor = Preprocessor(path=PATH_TEST_DATA,\n",
    "                                hu_min_value=0,\n",
    "                                hu_max_value=100,\n",
    "                                augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator_train = Data_Generator(train_data,\n",
    "                              train_preprocessor,\n",
    "                              32,\n",
    "                              shuffle=True,\n",
    "                              steps=50)\n",
    "\n",
    "data_generator_val = Data_Generator(val_data, \n",
    "                            val_preprocessor,\n",
    "                            32,\n",
    "                            shuffle=True,\n",
    "                            steps=50)\n",
    "\n",
    "data_generator_test= Data_Generator(test_df, \n",
    "                             test_preprocessor,\n",
    "                             16,\n",
    "                             shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.8819 - accuracy: 0.8500\n",
      "Epoch 00001: val_loss improved from inf to 0.70571, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 66s 1s/step - loss: 0.8791 - accuracy: 0.8502 - val_loss: 0.7057 - val_accuracy: 0.8702\n",
      "Epoch 2/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.6414 - accuracy: 0.8696\n",
      "Epoch 00002: val_loss improved from 0.70571 to 0.55132, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 60s 1s/step - loss: 0.6399 - accuracy: 0.8696 - val_loss: 0.5513 - val_accuracy: 0.8702\n",
      "Epoch 3/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.5168 - accuracy: 0.8681\n",
      "Epoch 00003: val_loss improved from 0.55132 to 0.46126, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 60s 1s/step - loss: 0.5161 - accuracy: 0.8682 - val_loss: 0.4613 - val_accuracy: 0.8702\n",
      "Epoch 4/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.4430 - accuracy: 0.8686\n",
      "Epoch 00004: val_loss improved from 0.46126 to 0.40829, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 59s 1s/step - loss: 0.4426 - accuracy: 0.8687 - val_loss: 0.4083 - val_accuracy: 0.8702\n",
      "Epoch 5/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.4038 - accuracy: 0.8677\n",
      "Epoch 00005: val_loss improved from 0.40829 to 0.37831, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 61s 1s/step - loss: 0.4036 - accuracy: 0.8676 - val_loss: 0.3783 - val_accuracy: 0.8701\n",
      "Epoch 6/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8688\n",
      "Epoch 00006: val_loss improved from 0.37831 to 0.36042, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 60s 1s/step - loss: 0.3812 - accuracy: 0.8687 - val_loss: 0.3604 - val_accuracy: 0.8702\n",
      "Epoch 7/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3631 - accuracy: 0.8691\n",
      "Epoch 00007: val_loss improved from 0.36042 to 0.35046, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 60s 1s/step - loss: 0.3629 - accuracy: 0.8691 - val_loss: 0.3505 - val_accuracy: 0.8701\n",
      "Epoch 8/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3550 - accuracy: 0.8704\n",
      "Epoch 00008: val_loss improved from 0.35046 to 0.34428, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 60s 1s/step - loss: 0.3545 - accuracy: 0.8704 - val_loss: 0.3443 - val_accuracy: 0.8707\n",
      "Epoch 9/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3505 - accuracy: 0.8675\n",
      "Epoch 00009: val_loss improved from 0.34428 to 0.34059, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 60s 1s/step - loss: 0.3504 - accuracy: 0.8674 - val_loss: 0.3406 - val_accuracy: 0.8713\n",
      "Epoch 10/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3466 - accuracy: 0.8681\n",
      "Epoch 00010: val_loss improved from 0.34059 to 0.33774, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 60s 1s/step - loss: 0.3466 - accuracy: 0.8682 - val_loss: 0.3377 - val_accuracy: 0.8712\n",
      "Epoch 11/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3445 - accuracy: 0.8686\n",
      "Epoch 00011: val_loss improved from 0.33774 to 0.33557, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 61s 1s/step - loss: 0.3441 - accuracy: 0.8687 - val_loss: 0.3356 - val_accuracy: 0.8720\n",
      "Epoch 12/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3439 - accuracy: 0.8687\n",
      "Epoch 00012: val_loss improved from 0.33557 to 0.33389, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 60s 1s/step - loss: 0.3438 - accuracy: 0.8689 - val_loss: 0.3339 - val_accuracy: 0.8711\n",
      "Epoch 13/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3403 - accuracy: 0.8700\n",
      "Epoch 00013: val_loss improved from 0.33389 to 0.33269, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 60s 1s/step - loss: 0.3401 - accuracy: 0.8703 - val_loss: 0.3327 - val_accuracy: 0.8735\n",
      "Epoch 14/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3387 - accuracy: 0.8704\n",
      "Epoch 00014: val_loss improved from 0.33269 to 0.33167, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 60s 1s/step - loss: 0.3387 - accuracy: 0.8704 - val_loss: 0.3317 - val_accuracy: 0.8739\n",
      "Epoch 15/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3376 - accuracy: 0.8705\n",
      "Epoch 00015: val_loss improved from 0.33167 to 0.33042, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 61s 1s/step - loss: 0.3375 - accuracy: 0.8707 - val_loss: 0.3304 - val_accuracy: 0.8736\n",
      "Epoch 16/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3374 - accuracy: 0.8703\n",
      "Epoch 00016: val_loss improved from 0.33042 to 0.32971, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 61s 1s/step - loss: 0.3375 - accuracy: 0.8702 - val_loss: 0.3297 - val_accuracy: 0.8745\n",
      "Epoch 17/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3339 - accuracy: 0.8705\n",
      "Epoch 00017: val_loss improved from 0.32971 to 0.32857, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 61s 1s/step - loss: 0.3337 - accuracy: 0.8707 - val_loss: 0.3286 - val_accuracy: 0.8745\n",
      "Epoch 18/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3332 - accuracy: 0.8706\n",
      "Epoch 00018: val_loss improved from 0.32857 to 0.32763, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 61s 1s/step - loss: 0.3333 - accuracy: 0.8706 - val_loss: 0.3276 - val_accuracy: 0.8751\n",
      "Epoch 19/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3355 - accuracy: 0.8705\n",
      "Epoch 00019: val_loss improved from 0.32763 to 0.32666, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 61s 1s/step - loss: 0.3352 - accuracy: 0.8707 - val_loss: 0.3267 - val_accuracy: 0.8736\n",
      "Epoch 20/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3335 - accuracy: 0.8714\n",
      "Epoch 00020: val_loss improved from 0.32666 to 0.32610, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 61s 1s/step - loss: 0.3332 - accuracy: 0.8713 - val_loss: 0.3261 - val_accuracy: 0.8748\n",
      "Epoch 21/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3314 - accuracy: 0.8706\n",
      "Epoch 00021: val_loss improved from 0.32610 to 0.32496, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 62s 1s/step - loss: 0.3311 - accuracy: 0.8705 - val_loss: 0.3250 - val_accuracy: 0.8758\n",
      "Epoch 22/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3325 - accuracy: 0.8693\n",
      "Epoch 00022: val_loss improved from 0.32496 to 0.32479, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 62s 1s/step - loss: 0.3325 - accuracy: 0.8692 - val_loss: 0.3248 - val_accuracy: 0.8738\n",
      "Epoch 23/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3306 - accuracy: 0.8715\n",
      "Epoch 00023: val_loss improved from 0.32479 to 0.32410, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 61s 1s/step - loss: 0.3305 - accuracy: 0.8712 - val_loss: 0.3241 - val_accuracy: 0.8768\n",
      "Epoch 24/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3312 - accuracy: 0.8707\n",
      "Epoch 00024: val_loss improved from 0.32410 to 0.32346, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 61s 1s/step - loss: 0.3314 - accuracy: 0.8708 - val_loss: 0.3235 - val_accuracy: 0.8756\n",
      "Epoch 25/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3262 - accuracy: 0.8706\n",
      "Epoch 00025: val_loss improved from 0.32346 to 0.32279, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 61s 1s/step - loss: 0.3259 - accuracy: 0.8709 - val_loss: 0.3228 - val_accuracy: 0.8753\n",
      "Epoch 26/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3294 - accuracy: 0.8714\n",
      "Epoch 00026: val_loss improved from 0.32279 to 0.32234, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 60s 1s/step - loss: 0.3293 - accuracy: 0.8714 - val_loss: 0.3223 - val_accuracy: 0.8747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3253 - accuracy: 0.8733\n",
      "Epoch 00027: val_loss improved from 0.32234 to 0.32148, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 62s 1s/step - loss: 0.3252 - accuracy: 0.8734 - val_loss: 0.3215 - val_accuracy: 0.8739\n",
      "Epoch 28/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3264 - accuracy: 0.8727\n",
      "Epoch 00028: val_loss improved from 0.32148 to 0.32114, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 61s 1s/step - loss: 0.3264 - accuracy: 0.8730 - val_loss: 0.3211 - val_accuracy: 0.8758\n",
      "Epoch 29/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3262 - accuracy: 0.8725\n",
      "Epoch 00029: val_loss improved from 0.32114 to 0.32110, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 61s 1s/step - loss: 0.3262 - accuracy: 0.8725 - val_loss: 0.3211 - val_accuracy: 0.8751\n",
      "Epoch 30/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3248 - accuracy: 0.8719\n",
      "Epoch 00030: val_loss improved from 0.32110 to 0.32017, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 62s 1s/step - loss: 0.3252 - accuracy: 0.8717 - val_loss: 0.3202 - val_accuracy: 0.8755\n",
      "Epoch 31/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3262 - accuracy: 0.8723\n",
      "Epoch 00031: val_loss improved from 0.32017 to 0.32015, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 61s 1s/step - loss: 0.3265 - accuracy: 0.8722 - val_loss: 0.3201 - val_accuracy: 0.8753\n",
      "Epoch 32/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3203 - accuracy: 0.8773\n",
      "Epoch 00032: val_loss improved from 0.32015 to 0.31919, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 62s 1s/step - loss: 0.3204 - accuracy: 0.8771 - val_loss: 0.3192 - val_accuracy: 0.8755\n",
      "Epoch 33/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3248 - accuracy: 0.8725\n",
      "Epoch 00033: val_loss improved from 0.31919 to 0.31918, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 62s 1s/step - loss: 0.3251 - accuracy: 0.8724 - val_loss: 0.3192 - val_accuracy: 0.8755\n",
      "Epoch 34/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3254 - accuracy: 0.8735\n",
      "Epoch 00034: val_loss improved from 0.31918 to 0.31867, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 62s 1s/step - loss: 0.3254 - accuracy: 0.8732 - val_loss: 0.3187 - val_accuracy: 0.8768\n",
      "Epoch 35/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3251 - accuracy: 0.8729\n",
      "Epoch 00035: val_loss did not improve from 0.31867\n",
      "51/51 [==============================] - 61s 1s/step - loss: 0.3248 - accuracy: 0.8730 - val_loss: 0.3187 - val_accuracy: 0.8755\n",
      "Epoch 36/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3230 - accuracy: 0.8731\n",
      "Epoch 00036: val_loss improved from 0.31867 to 0.31833, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 62s 1s/step - loss: 0.3232 - accuracy: 0.8732 - val_loss: 0.3183 - val_accuracy: 0.8768\n",
      "Epoch 37/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3250 - accuracy: 0.8706\n",
      "Epoch 00037: val_loss improved from 0.31833 to 0.31755, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 63s 1s/step - loss: 0.3251 - accuracy: 0.8706 - val_loss: 0.3176 - val_accuracy: 0.8769\n",
      "Epoch 38/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3215 - accuracy: 0.8741\n",
      "Epoch 00038: val_loss did not improve from 0.31755\n",
      "51/51 [==============================] - 62s 1s/step - loss: 0.3212 - accuracy: 0.8743 - val_loss: 0.3176 - val_accuracy: 0.8782\n",
      "Epoch 39/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3235 - accuracy: 0.8744\n",
      "Epoch 00039: val_loss improved from 0.31755 to 0.31742, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 63s 1s/step - loss: 0.3235 - accuracy: 0.8740 - val_loss: 0.3174 - val_accuracy: 0.8760\n",
      "Epoch 40/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3202 - accuracy: 0.8759\n",
      "Epoch 00040: val_loss improved from 0.31742 to 0.31683, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 61s 1s/step - loss: 0.3204 - accuracy: 0.8755 - val_loss: 0.3168 - val_accuracy: 0.8772\n",
      "Epoch 41/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3206 - accuracy: 0.8740\n",
      "Epoch 00041: val_loss improved from 0.31683 to 0.31622, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 61s 1s/step - loss: 0.3211 - accuracy: 0.8739 - val_loss: 0.3162 - val_accuracy: 0.8766\n",
      "Epoch 42/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3223 - accuracy: 0.8724\n",
      "Epoch 00042: val_loss improved from 0.31622 to 0.31585, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 61s 1s/step - loss: 0.3224 - accuracy: 0.8723 - val_loss: 0.3158 - val_accuracy: 0.8775\n",
      "Epoch 43/50\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.3193 - accuracy: 0.8739\n",
      "Epoch 00043: val_loss improved from 0.31585 to 0.31567, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 84s 2s/step - loss: 0.3192 - accuracy: 0.8739 - val_loss: 0.3157 - val_accuracy: 0.8780\n",
      "Epoch 44/50\n",
      "50/51 [============================>.] - ETA: 3s - loss: 0.3198 - accuracy: 0.8730\n",
      "Epoch 00044: val_loss improved from 0.31567 to 0.31491, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 260s 5s/step - loss: 0.3196 - accuracy: 0.8731 - val_loss: 0.3149 - val_accuracy: 0.8775\n",
      "Epoch 45/50\n",
      "50/51 [============================>.] - ETA: 3s - loss: 0.3220 - accuracy: 0.8745\n",
      "Epoch 00045: val_loss improved from 0.31491 to 0.31464, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 261s 5s/step - loss: 0.3221 - accuracy: 0.8746 - val_loss: 0.3146 - val_accuracy: 0.8772\n",
      "Epoch 46/50\n",
      "50/51 [============================>.] - ETA: 3s - loss: 0.3174 - accuracy: 0.8765\n",
      "Epoch 00046: val_loss did not improve from 0.31464\n",
      "51/51 [==============================] - 265s 5s/step - loss: 0.3176 - accuracy: 0.8764 - val_loss: 0.3148 - val_accuracy: 0.8793\n",
      "Epoch 47/50\n",
      "50/51 [============================>.] - ETA: 3s - loss: 0.3199 - accuracy: 0.8745\n",
      "Epoch 00047: val_loss improved from 0.31464 to 0.31434, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 254s 5s/step - loss: 0.3198 - accuracy: 0.8746 - val_loss: 0.3143 - val_accuracy: 0.8797\n",
      "Epoch 48/50\n",
      "50/51 [============================>.] - ETA: 3s - loss: 0.3204 - accuracy: 0.8753\n",
      "Epoch 00048: val_loss improved from 0.31434 to 0.31406, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 260s 5s/step - loss: 0.3205 - accuracy: 0.8755 - val_loss: 0.3141 - val_accuracy: 0.8790\n",
      "Epoch 49/50\n",
      "50/51 [============================>.] - ETA: 3s - loss: 0.3180 - accuracy: 0.8740\n",
      "Epoch 00049: val_loss improved from 0.31406 to 0.31365, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 254s 5s/step - loss: 0.3185 - accuracy: 0.8735 - val_loss: 0.3137 - val_accuracy: 0.8803\n",
      "Epoch 50/50\n",
      "50/51 [============================>.] - ETA: 3s - loss: 0.3216 - accuracy: 0.8731\n",
      "Epoch 00050: val_loss improved from 0.31365 to 0.31356, saving model to ../models/mymodels/\n",
      "51/51 [==============================] - 245s 5s/step - loss: 0.3220 - accuracy: 0.8731 - val_loss: 0.3136 - val_accuracy: 0.8804\n",
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "model2 = MakeModel(pt_model=my_vgg_16,\n",
    "                      loss=\"binary_crossentropy\", \n",
    "                      metrics_list=[\"accuracy\"],\n",
    "                      data_generator_train = data_generator_train,\n",
    "                      data_generator_val = data_generator_val,\n",
    "                      epochs=50,\n",
    "                      num_classes=6)\n",
    "model2.build_model()\n",
    "model2.compile_model()\n",
    "model2_history = model2.fit_model()\n",
    "\n",
    "print(model2_history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_10  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 100)               51300     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 14,766,594\n",
      "Trainable params: 51,906\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = model2_history.history['loss']\n",
    "val_loss = model2_history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "plt.plot(train_loss, label = 'training_loss', color = 'b')\n",
    "plt.plot(val_loss, label = 'val_loss', color = 'orange')\n",
    "\n",
    "plt.title('Training and Validation Loss by Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('weighted_log_loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = model2_history.history['accuracy']\n",
    "val_loss = model2_history.history['val_accuracy']\n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "plt.plot(train_loss, label = 'training_loss', color = 'b')\n",
    "plt.plot(val_loss, label = 'val_loss', color = 'orange')\n",
    "\n",
    "plt.title('Training and Validation Accuracy by Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-5f51b518dbe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_generator_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mval_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_generator_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "preds = model2.predict(data_generator_test)[0:test_df.shape[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape == test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121232, 6)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121232, 6)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(meta_data_df, predictions):\n",
    "    df = pd.DataFrame(predictions, columns=meta_data_df.columns, index=meta_data_df.index)\n",
    "    df = df.stack().reset_index()\n",
    "    df.loc[:, \"ID\"] = df.id.str.cat(df.subtype, sep=\"_\")\n",
    "    df = df.drop([\"id\", \"subtype\"], axis=1)\n",
    "    df = df.rename({0: \"Label\"}, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df = make_df(test_df, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df = test_pred_df[['ID','Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_000000e27_any</td>\n",
       "      <td>0.459186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_000000e27_epidural</td>\n",
       "      <td>0.017462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_000000e27_intraparenchymal</td>\n",
       "      <td>0.142150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_000000e27_intraventricular</td>\n",
       "      <td>0.081889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_000000e27_subarachnoid</td>\n",
       "      <td>0.184403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ID_000000e27_subdural</td>\n",
       "      <td>0.194744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ID_000009146_any</td>\n",
       "      <td>0.055589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ID_000009146_epidural</td>\n",
       "      <td>0.006816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ID_000009146_intraparenchymal</td>\n",
       "      <td>0.020436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ID_000009146_intraventricular</td>\n",
       "      <td>0.020102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ID     Label\n",
       "0               ID_000000e27_any  0.459186\n",
       "1          ID_000000e27_epidural  0.017462\n",
       "2  ID_000000e27_intraparenchymal  0.142150\n",
       "3  ID_000000e27_intraventricular  0.081889\n",
       "4      ID_000000e27_subarachnoid  0.184403\n",
       "5          ID_000000e27_subdural  0.194744\n",
       "6               ID_000009146_any  0.055589\n",
       "7          ID_000009146_epidural  0.006816\n",
       "8  ID_000009146_intraparenchymal  0.020436\n",
       "9  ID_000009146_intraventricular  0.020102"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df.to_csv('../data/output/submissions/submission_model_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7131371"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df[test_pred_df['Label'] <0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subtype\n",
       "any                 0.333333\n",
       "epidural            0.011642\n",
       "intraparenchymal    0.110907\n",
       "intraventricular    0.074142\n",
       "subarachnoid        0.111520\n",
       "subdural            0.146446\n",
       "dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.loc[data_generator_train.data_ids].sum() / train_data.loc[data_generator_train.data_ids].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727362</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727363</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727364</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727365</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727366</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727367</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727368</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727369</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727370</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727371</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727372</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727373</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727374</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727375</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727376</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727377</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727378</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727379</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727380</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727381</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727382</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727383</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727384</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727385</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727386</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727387</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727388</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727389</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727390</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727391</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>727392 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Label\n",
       "0       0    0.0\n",
       "1       0    0.0\n",
       "2       0    0.0\n",
       "3       0    0.0\n",
       "4       0    0.0\n",
       "5       0    0.0\n",
       "6       0    0.0\n",
       "7       0    0.0\n",
       "8       0    0.0\n",
       "9       0    0.0\n",
       "10      0    0.0\n",
       "11      0    0.0\n",
       "12      0    0.0\n",
       "13      0    0.0\n",
       "14      0    0.0\n",
       "15      0    0.0\n",
       "16      0    0.0\n",
       "17      0    0.0\n",
       "18      0    0.0\n",
       "19      0    0.0\n",
       "20      0    0.0\n",
       "21      0    0.0\n",
       "22      0    0.0\n",
       "23      0    0.0\n",
       "24      0    0.0\n",
       "25      0    0.0\n",
       "26      0    0.0\n",
       "27      0    0.0\n",
       "28      0    0.0\n",
       "29      0    0.0\n",
       "...    ..    ...\n",
       "727362  0    0.0\n",
       "727363  0    0.0\n",
       "727364  0    0.0\n",
       "727365  0    0.0\n",
       "727366  0    0.0\n",
       "727367  0    0.0\n",
       "727368  0    0.0\n",
       "727369  0    0.0\n",
       "727370  0    0.0\n",
       "727371  0    0.0\n",
       "727372  0    0.0\n",
       "727373  0    0.0\n",
       "727374  0    0.0\n",
       "727375  0    0.0\n",
       "727376  0    0.0\n",
       "727377  0    0.0\n",
       "727378  0    0.0\n",
       "727379  0    0.0\n",
       "727380  0    0.0\n",
       "727381  0    0.0\n",
       "727382  0    0.0\n",
       "727383  0    0.0\n",
       "727384  0    0.0\n",
       "727385  0    0.0\n",
       "727386  0    0.0\n",
       "727387  0    0.0\n",
       "727388  0    0.0\n",
       "727389  0    0.0\n",
       "727390  0    0.0\n",
       "727391  0    0.0\n",
       "\n",
       "[727392 rows x 2 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_cor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator_test = TestDataGenerator(dataset = test_df, batch_size = TEST_BATCH_SIZE,img_size = SHAPE,\n",
    "                                                        img_dir = PATH_TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_STEPS = int(len(data_generator_test) / TRAIN_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_STEPS = int(dest_df.shape[0] / TRAIN_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15154"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_generator_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15154/15154 [==============================] - 1119s 74ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = vgg19_model.predict_generator(generator = data_generator_test, \n",
    "                                      #steps = TEST_STEPS,\n",
    "                                      verbose = 1,\n",
    "                                      use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121232, 6)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121232, 6)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = preds[:test_df.iloc[range(test_df.shape[0])].shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(meta_data_df, predictions):\n",
    "    df = pd.DataFrame(predictions, columns=meta_data_df.columns, index=meta_data_df.index)\n",
    "    df = df.stack().reset_index()\n",
    "    df.loc[:, \"ID\"] = df.id.str.cat(df.subtype, sep=\"_\")\n",
    "    df = df.drop([\"id\", \"subtype\"], axis=1)\n",
    "    df = df.rename({0: \"Label\"}, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df = make_df(test_df, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(727392, 2)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 138s 585ms/step\n"
     ]
    }
   ],
   "source": [
    "val_preds= vgg19_model.predict_generator(generator = data_generator_val, verbose = 1, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15104, 6)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([    21,     48,    118,    174,    283,    349,    428,    445,\\n               454,    602,\\n            ...\\n            752328, 752333, 752358, 752454, 752539, 752560, 752592, 752621,\\n            752692, 752770],\\n           dtype='int64', name='subtype', length=15057)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-6faa440df6b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/conda/envs/nvidia-dsd-1.3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2932\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2933\u001b[0m             indexer = self.loc._convert_to_indexer(key, axis=1,\n\u001b[0;32m-> 2934\u001b[0;31m                                                    raise_missing=True)\n\u001b[0m\u001b[1;32m   2935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/nvidia-dsd-1.3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[1;32m   1353\u001b[0m                           raise_missing}\n\u001b[0;32m-> 1354\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/nvidia-dsd-1.3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[1;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/nvidia-dsd-1.3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1244\u001b[0m                 raise KeyError(\n\u001b[1;32m   1245\u001b[0m                     u\"None of [{key}] are in the [{axis}]\".format(\n\u001b[0;32m-> 1246\u001b[0;31m                         key=key, axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([    21,     48,    118,    174,    283,    349,    428,    445,\\n               454,    602,\\n            ...\\n            752328, 752333, 752358, 752454, 752539, 752560, 752592, 752621,\\n            752692, 752770],\\n           dtype='int64', name='subtype', length=15057)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "train_df[valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_df = make_df(val_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
